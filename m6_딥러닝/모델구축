
** 기본 구성 요소

모델 : Sequential 모델, 함수형 API로 신경망 구성

  Sequential 모델은 순차적으로 쌓는 간단한 방식

  함수형 API는 더 복잡한 모델을 구성할 수 있는 유연성 제공


레이어 : 모델 예측, 실제 값 사이의 차이를 측정하는 함수

  회귀 : mean_squared_error, 분류 : categorical_crossentropy


옵티마이저 : 경사하강법 알고리즘 구현

  adam, sgd, rmsprop ..

평가지표 : accuracy, precision, recall...


** 모델 구축 방법

Sequential API

  레이어를 순차적으로 쌓아 올리는 방식

  바로 이전 레이어의 출력을 입력으로 받아 처리

함수형 API

  더 유연한 모델 설계 가능해 복잡한 모델 아키텍처 구성

  다중 입력 및 출력, 공유 레이어, 레이어간 복잡한 연결 구조.. 정의



** 활성화 함수

  - ReLU : 계산 효율성이 높으면서도 비선형성이 도입되어 훈련 중에 모델이 빠르게 수렴될 수 있음

  - 시그모이드 : 0과 1사이의 값을 출력하므로 이진 분류에 적합

  - 소프트 맥스 : 각 클래스에 대한 확률을 얻기 위해 분류기의 출력 레이어에서 자주 사용

  -> 여러 클래스에 대한 확률 분포를 출력

  - Tanh(하이퍼볼릭 탄젠트) : 시그모이드와 비슷하지만 -1과 1사이의 값 출력


** 옵티마이저

  손실을 줄이기 위해 가중치, 학습률 등 신경망의 속성을 변경하는데 사용되는 알고리즘 또는 방법

  비용함수(손실함수)를 최소화하는 모델에 대한 최상의 매개변수(가중치) 찾는 것이 최적화 목표

  - 확률적 경사하강법(SGD) : 가장 간단한 최적화 프로그램 중 하나

    각 훈련 예제를 개별적으로 사용하여 모델의 가중치를 업데이트

  - 모멘텀 : SGD를 가속화하고 현재 업데이트 벡터에 과거 단계의 업데이트 벡터의 일부를 추가하여 높은 곡률 방향의 진동을 완화

  - Adagrad : 학습속도를 매개변수에 맞게 조정하여 자주 발생하는 기능과 관련된 매개변수에 대해 더 작은 업데이트 수행
  
    자주 발생하지 않는 기능과 관련된 매개변수에 대해 더 큰 업데이트를 수행

  - RMSprop : 가중치에 대한 학습률을 해당 가중치에 대한 최근 기울기 크기의 이동 평균으로 나눔

  - Adam : 최상의 속성을 결합하여 노이즈 문제에 대한 희소 기울기를 처리할 수 있는 최적 알고리즘 제공

** 손실함수

  - 평균 제곱 오차(MSE): 회귀 문제

    예측값과 실제값 사이의 오차 제곱의 평균을 계산

      keras.losses.MeanSquaredError()

- 이진 교차엔트로피: 이진 분류 문제

    두 확률 분포, 즉 실제 레이블 분포와 예측 확률 사이의 거리를 측정
    
    keras.losses.BinaryCrossentropy()

- 범주형 교차엔트로피: 레이블이 원-핫 인코딩되는 다중 클래스 분류 문제

    이진 교차엔트로피와 유사하지만 여러 클래스에 적용
    
    keras.losses.keras.losses.CategoricalCrossentropy()

- 희소 범주형 교차엔트로피: 범주형 교차엔트로피와 유사하지만 레이블이 정수인 경우에

    클래스가 많은 경우에는 메모리 효율성이 더 높음
    
    keras.losses.SparseCategoricalCrossentropy()

