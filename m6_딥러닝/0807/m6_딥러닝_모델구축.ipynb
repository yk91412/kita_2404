{"cells":[{"cell_type":"markdown","metadata":{"id":"uCqugyxiDszW"},"source":["## TensorFlow, Keras\n","딥러닝 모델을 개발, 훈련, 평가, 배포하는 데 필요한 도구와 라이브러리를 제공하며 딥러닝을 효율적이고 쉽게 구현할 수 있도록 다양한 기능을 갖추고 있는 딥러닝 프레임워크이다.\n","\n","- TensorFlow: 딥러닝 모델을 정의하고 구축할 수 있는 다양한 API를 제공합니다. 고수준 API(tf.keras)와 저수준 API를 통해 다양한 모델을 유연하게 설계할 수 있습니다.\n","- Keras: TensorFlow 위에서 작동하는 고수준 API로, 사용자가 간단하고 직관적으로 모델을 정의할 수 있게 도와줍니다. 직관적인 레이어 기반의 접근 방식을 사용해 빠르게 모델을 구축할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"PmxhdE-PDtdQ"},"source":["텐서플로우(TensorFlow)의 케라스(Keras)\n","\n","- 머신러닝 모델을 쉽고 빠르게 개발할 수 있도록 도와주는 고수준의 신경망 API. 원래 케라스는 독립적인 딥러닝 라이브러리로 시작되었지만, 텐서플로우 1.0 버전부터는 텐서플로우의 공식 프론트엔드로 통합되었고, 텐서플로우 2.0 이후부터는 텐서플로우의 기본 API로 자리잡았다.\n","- 케라스는 사용자 친화적이며 모듈식으로 구성되어 있어, 신경망의 레이어(layer), 활성화 함수(activation function), 손실 함수(loss function) 등을 마치 레고 블록을 조립하듯 쉽게 조합하여 모델을 구성할 수 있다. 이를 통해 컴퓨터 비전, 자연어 처리와 같은 다양한 머신러닝 애플리케이션을 신속하게 개발할 수 있다.\n","\n","주요 특징\n","\n","- 사용자 친화성: 케라스는 일관된 API를 제공하며, 일반적인 사용 사례에 대한 간결한 코드를 지향합니다. 이를 통해 사용자가 직관적으로 이해하고 사용할 수 있다.\n","- 모듈성: 모델은 독립적인 모듈, 즉 레이어, 손실 함수, 활성화 함수, 최적화 알고리즘 등의 조합으로 구성됩니다. 이러한 모듈은 최소한의 제약으로 서로 연결될 수 있어, 매우 유연한 모델 설계가 가능.\n","- 확장성: 케라스는 새로운 레이어나 기타 모듈을 만들어 추가하는 것이 상대적으로 쉽습니다. 따라서 연구 목적으로 새로운 아이디어를 실험하고자 할 때 매우 유용.\n","- 파이썬 기반: 케라스는 순수 파이썬으로 작성되어 있으며, 딥러닝 모델을 파이썬 코드로 쉽게 작성할 수 있다.\n","\n","기본 구성 요소\n","- 모델: Sequential 모델과 함수형 API를 통해 신경망을 구성할 수 있다. - Sequential 모델은 레이어를 순차적으로 쌓는 간단한 방식이며, 함수형 API는 더 복잡한 모델을 구성할 수 있는 유연성을 제공.\n","- 레이어: 다양한 유형의 레이어(예: Dense(완전 연결 레이어), Conv2D(2D 컨볼루션 레이어), RNN(재귀 신경망 레이어))를 제공.\n","- 손실 함수: 모델의 예측과 실제 값 사이의 차이를 측정하는 함수입니다. 예를 들어, 회귀 문제에는 mean_squared_error, 분류 문제에는 categorical_crossentropy가 자주 사용.\n","- 옵티마이저: 경사하강법 알고리즘을 구현한 것으로, adam, sgd, rmsprop 등이 있다. 모델의 손실을 최소화하기 위해 모델 파라미터를 업데이트하는 방법을 정의.\n","- 평가 지표: 학습과 테스트 단계에서 모델의 성능을 평가하기 위해 사용되는 지표들이다. 예를 들어, 정확도(accuracy), 정밀도(precision), 재현율(recall) 등이 있다.\n","\n","케라스는 이러한 구성 요소들을 사용하여 다양한 신경망 아키텍처를 구현하고, 이를 텐서플로우 백엔드를 통해 효율적으로 실행할 수 있게 해준다."]},{"cell_type":"markdown","metadata":{"id":"VQF5mXhmDwwb"},"source":["### 텐서플로우(TensorFlow) 모델 구축 방법\n","Sequential API와 함수형(Functional) API. 이 두 방법은 신경망 모델을 정의, 구축 및 실험하는 데 사용되며, 사용자의 필요와 모델의 복잡성에 따라 적합한 방법을 선택할 수 있다.\n","\n","Sequential API\n","- Sequential API는 가장 간단한 형태의 모델을 생성하는 방법 중 하나로, 레이어를 순차적으로 쌓아 올리는 방식으로 모델을 정의. 각 레이어는 바로 이전 레이어의 출력을 입력으로 받아 처리.\n","- Sequential 모델은 단순한 순차적 구조를 가진 신경망에 적합하며, 복잡한 모델 구조(예: 다중 입력/출력, 모델 내 레이어 간 병렬 연결 등)를 표현하는 데는 한계가 있다.\n","\n","함수형(Functional) API\n","- 함수형 API는 더 유연한 모델 설계를 가능하게 하는 API로, 복잡한 모델 아키텍처를 구성할 수 있다.\n","- 함수형 API를 사용하면 다중 입력 및 출력, 공유 레이어(동일한 레이어를 여러 번 사용), 레이어 간 복잡한 연결 구조 등을 정의할 수 있다. 이는 각 레이어의 입출력을 명시적으로 정의함으로써 달성된다. 함수형 API는 고급 사용자에게 더 많은 유연성과 제어력을 제공한다."]},{"cell_type":"markdown","metadata":{"id":"d0UPO9BGOpg9"},"source":["[ 활성화 함수 ]\n","- ReLU(Rectified Linear Unit): 'f(x) = max(0, x)'로 정의되어 널리 사용되는 활성화 함수입니다. 계산 효율성이 높으면서도 비선형성이 도입되어 훈련 중에 모델이 빠르게 수렴될 수 있다.\n","- 시그모이드: 이 활성화 함수는 0과 1 사이의 값을 출력하므로 이진 분류 문제에 적합.\n","- 소프트맥스: 각 클래스에 대한 확률을 얻기 위해 분류기의 출력 레이어에서 자주 사용되는 소프트맥스 함수는 여러 클래스에 대한 확률 분포를 출력.\n","- Tanh(하이퍼볼릭 탄젠트): 시그모이드와 비슷하지만 -1과 1 사이의 값을 출력."]},{"cell_type":"markdown","metadata":{"id":"g68Df471JC4G"},"source":["Q. sequential 모델을 사용하여 간단한 완전 연결 신경망 구성\n","\n","- 입력 레이어는 28*28의 입력 특성을 가진 입력 레이어\n","- 은닉 레이어는 32개의 뉴런을 가지고 있고, ReLU 활성화 함수 사용\n","- 은닉 레이어는 64개의 뉴런을, ReLU 활성화 함수 사용\n","- 출력 레이어는 10개의 뉴런을 가지고 있고, 소프트 맥스 활성화 함수 사용"]},{"cell_type":"markdown","metadata":{"id":"4q2jic5NOy4-"},"source":["픽셀이 28*28인 손글씨 이미지를 분류해주는 모델 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gM3lvhkcDW6Z"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense,Input\n","\n","model = Sequential([\n","    Input(shape=(28*28,)),\n","    Dense(32, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(10, activation='softmax')\n","])"]},{"cell_type":"markdown","metadata":{"id":"1a8cFcxBPYrI"},"source":["- 신경망 및 딥러닝의 맥락에서 옵티마이저는 손실을 줄이기 위해 가중치, 학습률 등 신경망의 속성을 변경하는 데 사용되는 알고리즘 또는 방법.\n","- 옵티마이저는 학습 프로세스의 속도와 품질에 직접적인 영향을 미치므로 학습 프로세스에 매우 중요.\n","- 최적화의 목표는 비용 함수(또는 손실 함수)를 최소화하는 모델에 대한 최상의 매개변수(가중치)를 찾는 것이다. 이 프로세스는 모델이 특정 작업에 대한 정확성과 성능을 향상시키는 데 필수적이다.\n","\n","[ 옵티마이저 유형 ]\n","\n","가중치를 조정하기 위한 자체 메커니즘과 전략을 가진 여러 가지 최적화 프로그램이 있습니다. 가장 일반적으로 사용되는 최적화 도구는 다음과 같다.\n","\n","- 확률적 경사하강법(SGD): 이것은 가장 간단한 최적화 프로그램 중 하나. 각 훈련 예제를 개별적으로 사용하여 모델의 가중치를 업데이트. 여기에는 각 단계에서 훈련 데이터의 하위 집합을 사용하여 더 효율적으로 만드는 미니 배치 경사하강법(Mini-Batch Gradient Descent)과 같은 변형이 있다.\n","- 모멘텀: 이 최적화 프로그램은 관련 방향을 따라 탐색하여 SGD를 가속화하고 현재 업데이트 벡터에 과거 단계의 업데이트 벡터의 일부를 추가하여 높은 곡률 방향의 진동을 완화.\n","- Adagrad: 학습 속도를 매개변수에 맞게 조정하여 자주 발생하는 기능과 관련된 매개변수에 대해 더 작은 업데이트를 수행하고, 자주 발생하지 않는 기능과 관련된 매개변수에 대해 더 큰 업데이트를 수행.\n","- RMSprop: 이 최적화 프로그램은 가중치에 대한 학습률을 해당 가중치에 대한 최근 기울기 크기의 이동 평균으로 나눈다. 이는 Geoff Hinton이 강의에서 제안한 미공개 적응형 학습률 방법.\n","- Adam(Adaptive Moment Estimation): AdaGrad 및 RMSprop 알고리즘의 최상의 속성을 결합하여 노이즈 문제에 대한 희소 기울기를 처리할 수 있는 최적화 알고리즘을 제공.\n","\n","[ 옵티마이저 작동 방식 ]\n","\n","- 최적화 프로그램은 모델 매개변수에 대한 손실 함수의 기울기를 사용하여 조정. 이 기울기는 손실을 최소화하기 위해 가중치를 조정해야 하는 방향을 나타낸다. 가중치를 반복적으로 업데이트함으로써 최적화 프로그램은 모델의 최고 성능에 해당하는 손실 함수의 가장 낮은 지점에 도달하려고 한다.\n","- 최적화 프로그램의 선택은 신경망의 성능에 큰 영향을 미칠 수 있으며, 최선의 선택은 특정 문제, 데이터의 성격, 신경망 아키텍처에 따라 달라질 수 있다. Adam은 다양한 문제에 대한 적응성과 성능으로 인해 기본적으로 좋은 선택이 되는 경우가 많지만, 특정 작업과 데이터 세트에는 다른 최적화 프로그램이 도움이 될 수 있다. 주어진 시나리오에 가장 효과적인 최적화 프로그램을 식별하려면 일반적으로 실험과 교차 검증이 필요하다."]},{"cell_type":"markdown","metadata":{"id":"8zjoMZ4MPa2N"},"source":["[ 손실 함수라고도 알려진 비용 함수 ]\n","- 모델의 예측 출력과 실제 목표 값 간의 차이를 측정하는 수학적 함수입니다. 이는 모델의 오류를 정량화하여 훈련 중 최적화 프로세스에 대한 가이드 역할을 한다.\n","- 신경망 훈련의 목표는 이 비용 함수를 최소화하는 것이다. 이는 모델이 예측하는 것과 실제로 관찰되는 것 사이의 오류를 효과적으로 줄이는 것을 의미.\n","- 고급 신경망 API인 Keras는 다양한 유형의 문제에 대해 다양한 비용 함수를 내장하고 있으며 필요한 경우 사용자 정의 손실 함수를 생성할 수도 있다. 비용 함수의 선택은 분류, 회귀 등과 같이 해결되는 문제의 구체적인 성격에 따라 달라다.\n","\n","[ Keras의 일반적인 비용 함수 ]\n","- 평균 제곱 오차(MSE): 회귀 문제에 사용됩니다. 예측값과 실제값 사이의 오차 제곱의 평균을 계산. keras.losses.MeanSquaredError()\n","- 이진 교차엔트로피: 이진 분류 문제에 사용됩니다. 두 확률 분포, 즉 실제 레이블 분포와 예측 확률 사이의 거리를 측정. keras.losses.BinaryCrossentropy()\n","- 범주형 교차엔트로피: 레이블이 원-핫 인코딩되는 다중 클래스 분류 문제에 사용. 이진 교차엔트로피와 유사하지만 여러 클래스에 적용. keras.losses.keras.losses.CategoricalCrossentropy()\n","- 희소 범주형 교차엔트로피: 범주형 교차엔트로피와 유사하지만 레이블이 정수인 경우에 사용됩니다. 클래스가 많은 경우에는 메모리 효율성이 더 높다. keras.losses.SparseCategoricalCrossentropy()"]},{"cell_type":"markdown","metadata":{"id":"C7DKuOTUTBAR"},"source":["Q. 모델 컴파일하기  = 옵티마이저, 손실함수, 평가지표 설정하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cf8Y9tAbKAs8"},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"aBIYCgTQVBvB"},"source":["[ 배치 크기 ]\n","- 배치 크기는 기계 학습에 사용되는 용어로, 모델 학습 프로세스의 한 번의 반복에서 활용되는 학습 예제의 수를 나타낸다.\n","- 신경망 훈련의 맥락에서 데이터 세트는 일반적으로 여러 배치로 나뉘며 모델의 가중치는 각 배치를 처리한 후 업데이트된다.\n","- 배치 크기의 선택은 수렴 속도와 훈련 프로세스의 안정성을 포함한 훈련 역학에 큰 영향을 미칠 수 있다.\n","\n","- 작은 배치 크기: 각 업데이트 내에서 더 많은 노이즈로 더 빠른 업데이트가 가능. 이는 때때로 모델이 로컬 최소값을 벗어나는 데 도움이 될 수 있지만 훈련 과정을 더욱 불안정하게 만들 수도 있다.\n","- 대형 배치 크기: 기울기에 대한 더 정확한 추정치를 제공하며 업데이트 시 노이즈가 적다. 이는 더 안정적이지만 잠재적으로 더 느린 훈련으로 이어질 수 있습니다. 또한 대규모 배치에는 더 많은 메모리가 필요하므로 일부 하드웨어에서는 제한 요소가 될 수 있다.\n","\n","[ 에포크 ]\n","- 에포크는 전체 훈련 데이터세트를 한 번 통과하는 것을 나타낸다. 한 epoch 동안 신경망은 모든 훈련 예제를 한 번 처리한다. 따라서 훈련의 에포크 수에 따라 학습 알고리즘이 전체 훈련 데이터 세트에서 작동하는 횟수가 결정된다.\n","- 너무 적은 에포크를 실행하면 모델이 훈련 데이터에서 충분히 학습하지 못하는 과소적합이 발생할 수 있다.\n","- 너무 많은 에포크를 실행하면 과적합이 발생할 수 있다. 즉, 모델이 노이즈를 포함하여 훈련 데이터에서 패턴을 너무 잘 학습하여 보이지 않는 데이터에 대한 성능이 저하될 수 있다.\n","\n","[ 배치 크기와 에포크 간의 관계 ]\n","- 배치 크기 영향: 배치 크기는 가중치를 업데이트하기 전에 확인하는 예시 수를 결정. 배치가 작을수록 한번에 더 많은 업데이트가 이루어지며 잠재적으로 학습 속도가 빨라지지만 너무 작으면 불안정해질 수 있다. 배치가 클수록 더 안정적인 기울기 추정이 제공되지만 학습 속도가 느려지고 더 많은 메모리가 필요할 수 있다.\n","- 에포크 영향: 에포크 수에 따라 학습 알고리즘이 전체 데이터 세트를 순환하는 횟수가 결정. Epoch가 많을수록 모델이 가중치를 학습하고 조정할 수 있는 기회가 더 많아지지만 숫자가 너무 높으면 과적합이 발생할 위험이 있다.\n","- 요약하자면, 배치 크기와 에포크 수는 신중하게 균형을 맞춰야 하는 신경망 훈련의 두 가지 기본 하이퍼파라미터이다. 이러한 매개변수의 최적 설정은 특정 데이터세트와 문제는 물론 사용 가능한 계산 리소스에 따라 달라진다."]},{"cell_type":"markdown","metadata":{"id":"hOX2xlKcU80l"},"source":["Q. 모델을 간단한 데이터셋에 적용하여 학습하기\n","\n","- MNIST 데이터셋을 사용\n","- 배치 사이즈는 32, 에포크 수는 10으로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40598,"status":"ok","timestamp":1722908817810,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"K-OgwqiYW5tr","outputId":"5122a362-7914-4d37-ba14-db045d04ba5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.5828\n","Epoch 2/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1635\n","Epoch 3/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1249\n","Epoch 4/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0978\n","Epoch 5/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.0861\n","Epoch 6/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0720\n","Epoch 7/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0644\n","Epoch 8/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0553\n","Epoch 9/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0525\n","Epoch 10/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0471\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7c9730aa3700>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# 데이터 로드\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","# 데이터 전처리\n","train_images = train_images.reshape((60000, 784)).astype('float32') / 255\n","test_images = test_images.reshape((10000, 784)).astype('float32') / 255\n","\n","# 레이블을 원-핫 인코딩\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","model.fit(train_images, train_labels, epochs=10, batch_size=32)\n"]},{"cell_type":"markdown","metadata":{"id":"5h60f0oSXMxf"},"source":["Q. 모델 평가하기\n","\n","- 테스트 데이터 셋을 사용하여 모델 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1236,"status":"ok","timestamp":1722908856230,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"3KLUz1-FXG7J","outputId":"dc8bc3df-f19d-470d-96b8-fc455872a61d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.1136\n","Test accuracy :  0.9713000059127808\n"]}],"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print('Test accuracy : ', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"elapsed":548,"status":"ok","timestamp":1722908871634,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"bYEkSwONXuXE","outputId":"1bbb7122-9bff-4012-f699-c975e32b2c7b"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_4\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m25,120\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,648</span> (326.75 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,648\u001b[0m (326.75 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,882</span> (108.91 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,882\u001b[0m (108.91 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,766</span> (217.84 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m55,766\u001b[0m (217.84 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"gKjOTgL7bslu"},"source":["Q. MNIST 데이터셋에 대하여 Sequential 모델을 사용하여 간단한 완전 연결 신경망(Feedforward Neural Network) 구성하세요.\n","- 입력 형태(input_shape): input_shape=(28, 28)로 설정. 이는 모델이 28x28 픽셀 크기의 이미지를 입력으로 받는다는 것을 의미이며 첫 번째 레이어인 Flatten은 이 2D 이미지를 784(28x28) 요소의 1D 배열로 평탄화.Flatten(input_shape=(28, 28))\n","\n","- 레이어 구성: 모델은 평탄화 레이어(Flatten) 다음에 128개의 뉴런을 가진 완전 연결 레이어(Dense)를 가지고 있으며, 그 다음에는 10개의 출력 뉴런을 가진 또 다른 Dense 레이어가 있다. 출력 레이어는 소프트맥스 활성화 함수를 사용하여 다중 클래스 분류를 수행.\n","\n","- 컴파일:\n","  - optimizer='adam',\n","  - loss='sparse_categorical_crossentropy',\n","  - metrics=['accuracy']\n","\n","- epochs=5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BhTwkNPAbvPP"},"outputs":[],"source":["# 입력 데이터가 1차원 벡터로 이미 변환한 상태\n","Input(shape(28*28)),\n","# 2차원 입력 이미지를 1차원 벡터로 평탄화\n","Flatten(input_shape(28,28))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3789,"status":"ok","timestamp":1722912262935,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"Sul9T19acsdf","outputId":"14d035cd-7c28-4a53-b7e2-7ad677a6590d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense,Input, Flatten\n","\n","model = Sequential([\n","    Flatten(input_shape=(28, 28)),\n","    # Inut(shape=(28*28))\n","    # Flatten()\n","    Dense(128, activation='relu'),\n","    Dense(10, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HO9arZOxc2pS"},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25341,"status":"ok","timestamp":1722912312640,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"ZVFO-019dCUY","outputId":"fa05589a-2b35-4ce9-bb70-57547a8a0e51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.4319\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1192\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0762\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9813 - loss: 0.0578\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0442\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x7cee01b231c0>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# mnist = tf.keras.datasets.mnist\n","(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n","\n","# 최대 정수가 255이므로 0과 1로 정규화 가능\n","train_images = train_images / 255\n","test_images = test_images / 255\n","\n","\n","model.fit(train_images, train_labels, epochs=5, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1796,"status":"ok","timestamp":1722912316303,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"LWquv8Mhh2QR","outputId":"f7035ad8-afcd-4e81-c127-a1391f9c2d58"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0850\n","Test accuracy :  0.9786999821662903\n"]}],"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print('Test accuracy : ', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"elapsed":542,"status":"ok","timestamp":1722912325291,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"dDLFrQNuhRN_","outputId":"560a1f41-c657-404c-e648-9cd84938032d"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,312</span> (1.16 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m305,312\u001b[0m (1.16 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,542</span> (795.09 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m203,542\u001b[0m (795.09 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"KKHs_ZeAkVq9"},"source":["각 레이어의 파라미터 개수 계산\n","- Input 레이어: 파라미터가 없습니다.\n","\n","- Flatten 레이어: 파라미터가 없습니다. 입력 형태를 (28, 28)에서 (784,)로 변환합니다.\n","\n","- 첫 번째 Dense 레이어: 입력 뉴런 784개, 출력 뉴런 128개\n","  - 파라미터 개수 = 784 * 128 + 128 = 100,480\n","  - 각 입력 뉴런이 각 출력 뉴런과 연결되므로, 총 가중치 파라미터 수는 784 x 128이고 각 출력 뉴런마다 하나의 바이어스 파라미터가 추가되어 128개 추가\n","- 두 번째 Dense 레이어: 입력 뉴런 128개, 출력 뉴런 10개\n","  - 파라미터 개수 = 128 * 10 + 10 = 1290"]},{"cell_type":"markdown","metadata":{"id":"Drv_nwnHlU33"},"source":["[ 완전신경망(완전연결신경망, Fully Connected Neural Network)에서 각 층의 파라미터 수 계산 ]\n","\n","- 각 연결에 하나의 가중치가 있으므로, 특정 층의 가중치 수는 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱한 값과 같다.\n","- 각 뉴런에는 하나의 편향이 있으므로, 특정 층의 편향 수는 해당 층의 뉴런 수와 같다.\n","- 특정 층의 총 파라미터 수는 가중치 수와 편향 수의 합이다.\n","\n","가중치의 의미\n","- 이전 층의 뉴런 수: 각 뉴런은 이전 층의 모든 뉴런으로부터 입력 신호를 받는다. 이전 층에 더 많은 뉴런이 있을수록, 현재 층의 한 뉴런이 처리해야 할 입력 신호의 수가 더 많아진다.\n","- 해당 층의 뉴런 수: 해당 층에 더 많은 뉴런이 있다는 것은, 이전 층의 각 뉴런으로부터 오는 신호를 받아들이는 더 많은 처리 단위가 있다는 것을 의미.\n","- 가중치의 역할: 각 가중치는 입력 신호의 중요도를 조정. 즉, 특정 입력이 해당 뉴런의 활성화에 얼마나 영향을 미치는지 결정하는 역할을 한다. 가중치는 학습 과정에서 조정되며, 신경망이 훈련 데이터로부터 패턴을 학습하는 방식을 결정.\n","\n","가중치 수 계산\n","- 신경망에서 정보가 전달되는 방식과 학습이 어떻게 이루어지는지를 나타낸다. 각 가중치는 이전 층의 특정 뉴런과 현재 층의 특정 뉴런 사이의 연결 강도를 나타내며 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱하는 것은 모든 가능한 연결을 고려하여 이들 간의 관계를 정량화하는 방법이다.\n","- 계산 과정을 통해 각 연결마다 하나의 고유한 가중치가 할당"]},{"cell_type":"markdown","metadata":{"id":"PpAa5sfbloXg"},"source":["[ 픽셀(pixel) ]\n","- 디지털 이미지를 구성하는 기본 단위. 단어 \"픽셀\"은 \"Picture Element\"의 줄임말로, 이미지를 구성하는 가장 작은 단일 색상의 점을 의미. 각 픽셀은 특정 색상과 밝기 값을 가지며, 이러한 픽셀들이 모여 전체 이미지를 형성\n","- 색상과 밝기: 컬러 이미지에서 각 픽셀은 일반적으로 빨강(Red), 초록(Green), 파랑(Blue)의 세 가지 색상 채널 값을 가지며, 이를 RGB 값이라고 한다. 각 채널의 값은 보통 0에서 255 사이의 정수로 표현되며, 이 값들의 조합을 통해 다양한 색상을 나타낸다. 그레이스케일 이미지에서는 단일 채널만 사용하여 밝기를 표현하며, 0은 검은색, 255는 흰색을 의미하고, 그 사이의 값은 다양한 회색 음영을 나타낸다.\n","- 해상도: 이미지의 해상도는 이미지의 세부 사항과 선명도를 결정하는 중요한 요소입니다. 해상도가 높은 이미지는 더 많은 픽셀을 가지며, 따라서 더 세밀한 디테일을 표현할 수 있다. 예를 들어, 1920x1080 해상도의 이미지는 가로 1920픽셀, 세로 1080픽셀로 구성되어 있다.\n","- 디지털 표현: 디지털 이미지 처리, 컴퓨터 그래픽, 디지털 카메라 촬영과 같은 분야에서 픽셀은 기본적인 작업 단위로 사용되며 이미지의 품질, 색상 처리, 이미지 분석 등은 모두 픽셀 데이터를 기반으로 한다."]},{"cell_type":"markdown","metadata":{"id":"gXJ692p4qP3s"},"source":["[ Mnist데이터셋 ]\n","\n","- 입력 크기가 (28, 28)인 것은 각 이미지가 28픽셀의 너비와 28픽셀의 높이를 가진 2차원 그레이스케일 이미지라는 것을 의미\n","- 각 이미지는 단일 색상 채널(그레이스케일)을 가지며, 픽셀 값은 일반적으로 0(완전 검정)에서 255(완전 백색) 사이의 값을 가진다. 따라서, 각 이미지는 28x28=784개의 픽셀로 구성되며, 각 픽셀은 해당 위치에서의 밝기 또는 색상 강도를 나타낸다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1722913914875,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"l-sf1Crijbmr","outputId":"389564ab-e7a1-4526-d270-c12d1486186f"},"outputs":[{"data":{"text/plain":["(28, 28)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n","\n","train_images[0].shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":114},"executionInfo":{"elapsed":561,"status":"ok","timestamp":1722913981770,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"0yOq8Q6XrA0t","outputId":"37ea28fa-5d0e-46f1-8687-dee8f3965c88"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 100x100 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","image_data = train_images[0]\n","\n","plt.figure(figsize=(1,1))\n","plt.imshow(image_data, cmap='gray')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":536,"status":"ok","timestamp":1722914039641,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"GGGI8Hf4rRfg","outputId":"297c7774-db41-4488-a46b-20b7e1470999"},"outputs":[{"data":{"text/plain":["(784,)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_images[1].reshape(784,).shape"]},{"cell_type":"markdown","metadata":{"id":"W7Jaa5FMr5XX"},"source":["MNIST 데이터세트의 모양을 (60000, 28, 28)에서 (60000, 784)로 변경하는 이유\n","- 기계 학습의 일반적인 전처리 단계이며, 특히 완전히 연결된(밀집된) 신경망의 맥락에서 필요하며 이 프로세스를 이미지 \"평탄화\"라고 한다.\n","\n","[ 주요 이유 ]\n","- 신경망의 입력 형식: 신경망의 완전 연결된 레이어에서는 입력이 1D 벡터일 것으로 예상. 각 입력 뉴런은 다음 레이어의 모든 출력 뉴런에 연결.\n","- 이미지의 원래 2D 구조(28x28픽셀)는 공간 정보를 2차원으로 표현하기 때문에 이러한 기대에 맞지 않다. 이미지를 1D 벡터(이 경우 784개 요소)로 평면화하면 각 픽셀이 네트워크에 제공될 수 있는 개별 특징이 된다.\n","- 단순화: 평면화는 정보 손실 없이 데이터 구조를 단순화. 각 픽셀 값은 여전히 ​​전체 입력에 기여하지만 네트워크 계층에서 수행되는 수학적 연산(예: 내적)과 호환되는 형식.\n","- 네트워크 아키텍처와의 호환성: 대부분의 기본 신경망 아키텍처, 특히 입문 목적이나 간단한 작업에 사용되는 아키텍처는 다차원 데이터가 아닌 기능 벡터로 작동하도록 설계. CNN(컨벌루션 신경망)은 다차원 데이터를 직접 처리할 수 있지만(픽셀 간 공간 계층 보존) 완전 연결된 네트워크는 본질적으로 이러한 데이터를 처리하지 않는다.\n","- 효율성: 평면화된 이미지로 작업하는 것은 때때로 특정 작업에 대해 계산적으로 더 효율적일 수 있다. 특히 신경망에서 데이터 배치를 처리하기 위해 행렬 곱셈을 사용할 때 더욱 그렇다.\n","- 그러나 병합하면 픽셀 간의 공간적 관계가 삭제된다는 점에 유의하는 것이 중요. 이는 이미지 인식이나 객체 위치 파악과 같이 픽셀의 공간적 배열이 중요한 작업에는 적합하지 않다. 이러한 작업의 경우 CNN(컨벌루션 신경망)이 공간 계층을 유지하면서 2D 이미지를 처리할 수 있어 네트워크가 픽셀 배열을 기반으로 더 복잡한 패턴을 학습할 수 있으므로 더 적합하다."]},{"cell_type":"markdown","metadata":{"id":"yHs5iyHatMrl"},"source":["[ 레이블이 원-핫 인코딩되지 않은 이유 ]\n","\n","모델의 손실 함수(loss function)로 'sparse_categorical_crossentropy'가 사용되기 때문. TensorFlow와 Keras에서 두 가지 유형의 크로스엔트로피 손실 함수를 제공하며, 각각은 다음과 같은 경우에 사용된다:\n","\n","- 'sparse_categorical_crossentropy': 이 손실 함수는 레이블이 정수 형태로 제공될 때 사용. 즉, 각 샘플에 대해 단일 정수로 클래스 레이블이 지정되며, 이 경우 원-핫 인코딩을 할 필요가 없다. 이 함수는 내부적으로 정수 레이블을 적절한 원-핫 인코딩 형태로 변환하여 처리.\n","\n","- 'categorical_crossentropy': 이 손실 함수는 레이블이 원-핫 인코딩된 형태로 제공될 때 사용. 각 샘플의 레이블이 벡터이며, 벡터의 각 원소는 해당 클래스의 소속 여부를 나타낸다(클래스에 속하면 1, 아니면 0)."]},{"cell_type":"markdown","metadata":{"id":"nR2Gq4netfG1"},"source":["### Convolutional Neural Network (CNN)\n","CNN은 컨벌루션 레이어와 풀링 레이어를 사용하여 이미지의 공간 계층 구조를 캡처할 수 있기 때문에 이미지 처리 작업에 특히 적합\n","\n","[ CNN 아키텍처 ]\n","- 컨볼루션 레이어(Conv2D): 이 레이어는 컨볼루션 작업을 수행하여 이미지에서 공간 특징을 캡처.\n","- 풀링 레이어 (MaxPooling2D): 이 레이어는 다음 컨벌루션 레이어에 대한 입력 볼륨의 공간 크기(높이 및 너비)를 줄인다. 이는 계산 부하와 메모리 사용량을 줄이고 표현의 추상화된 형식을 제공하여 과적합을 줄이는 데 사용.\n","- 밀집 레이어(완전 연결 레이어): 여러 컨볼루션 및 풀링 레이어 이후 신경망의 상위 수준 추론은 컨볼루션 레이어에서 추출하고 평면화한 특징을 기반으로 분류를 수행하는 Dense 레이어를 통해 수행.\n","- 모델은 컨벌루션 레이어와 밀집 레이어에 'relu' 활성화를 사용(10자리 클래스에 대한 확률을 출력하기 위해 'softmax'를 사용하는 출력 레이어 제외). 다중 클래스 분류 작업에 적합한 adam 최적화 프로그램과 categorical_crossentropy 손실 함수로 컴파일.\n","\n","이 CNN 아키텍처를 사용하면 MNIST와 같은 이미지 분류 작업에서 높은 정확도를 달성하는 데 중요한 이미지 내 공간 관계를 활용할 수 있다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31862,"status":"ok","timestamp":1722915649068,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"l6pcnYzqrYPE","outputId":"8341da52-1d14-4e40-cb89-282a172cafe7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.2952\n","Epoch 2/5\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0374\n","Epoch 3/5\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0222\n","Epoch 4/5\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0140\n","Epoch 5/5\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0135\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0359\n","Test accuracy: 0.9919000267982483\n"]}],"source":["from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000,28,28,1)).astype('float32') / 255\n","test_images = test_images.reshape((10000,28,28,1)).astype('float32') /255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","model = models.Sequential()\n","\n","model.add(layers.InputLayer(shape=(28,28,1)))\n","model.add(layers.Conv2D(32,(3,3), activation='relu'))\n","model.add(layers.Conv2D(64,(3,3),activation='relu'))\n","model.add(layers.MaxPooling2D((2,2))) # 입력 이미지의 크기를 줄이는 데 사용되며 주요 특징을 유지하면서 계산량을 줄인다\n","model.add(layers.Conv2D(64,(3,3),activation='relu'))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)\n","\n","test_loss, test_acc = model.evaluate(test_images,test_labels)\n","print(f\"Test accuracy: {test_acc}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1722915664161,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"BNLSKNn5xpul","outputId":"752dddbf-31e6-4774-e7e6-d7252f4f1a76"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">409,664</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m409,664\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,398,176</span> (5.33 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,398,176\u001b[0m (5.33 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466,058</span> (1.78 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m466,058\u001b[0m (1.78 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">932,118</span> (3.56 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m932,118\u001b[0m (3.56 MB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"9du7RMPtzkym"},"source":["Task1_0806. 다음 사항을 준수하여 Fashion MNINS 데이터셋에 대하여 Sequential 방식으로 모델 생성 및 평가를 수행하세요.\n","- 입력 계층 및 첫 번째 Dense 계층 : 출력 512, activation='relu'\n","- 두 번째 Dense 계층 : 출력 256, activation='relu'\n","- 출력 계층 : 출력 10, activation='softmax'\n","- 모델 컴파일 : optimizer='adam', loss='categorical_crossentropy',         metrics=['accuracy']\n","- 모델 학습 : epochs=10, batch_size=64"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25547,"status":"ok","timestamp":1722990001461,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"Ab41wxX8zlW8","outputId":"8121ad40-b2cf-4b15-e844-b80920879996"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.6003\n","Epoch 2/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3613\n","Epoch 3/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.3187\n","Epoch 4/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2972\n","Epoch 5/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.2782\n","Epoch 6/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2611\n","Epoch 7/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.2497\n","Epoch 8/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2347\n","Epoch 9/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2274\n","Epoch 10/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2151\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.3432\n","Test accuracy: 0.8834999799728394\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Fashion MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","train_images = train_images.reshape((60000,28*28)).astype('float32') / 255\n","test_images = test_images.reshape((10000,28*28)).astype('float32') /255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","model = models.Sequential()\n","\n","model.add(layers.InputLayer(input_shape=(28*28,)))\n","\n","\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=10, batch_size=64)\n","\n","test_loss, test_acc = model.evaluate(test_images,test_labels)\n","print(f\"Test accuracy: {test_acc}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhU0oZoxN9nQ"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Fashion MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66},"executionInfo":{"elapsed":666,"status":"ok","timestamp":1722990197628,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"4_VtfhUyN3Em","outputId":"0a91a424-021d-49d4-a476-b3b24fa3fff9"},"outputs":[{"data":{"text/html":["<style>\n","      .ndarray_repr .ndarray_raw_data {\n","        display: none;\n","      }\n","      .ndarray_repr.show_array .ndarray_raw_data {\n","        display: block;\n","      }\n","      .ndarray_repr.show_array .ndarray_image_preview {\n","        display: none;\n","      }\n","      </style>\n","      <div id=\"id-3003581c-80d9-484c-a68c-701e01b6a3e7\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n","          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n","          1,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n","          0,   3],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n","          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n","         10,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n","         72,  15],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n","         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n","        172,  66],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n","        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n","        229,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n","        173,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n","        202,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n","        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n","        209,  52],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n","        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n","        167,  56],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n","        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n","         92,   0],\n","       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n","        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n","         77,   0],\n","       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n","        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n","        159,   0],\n","       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n","        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n","        215,   0],\n","       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n","        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n","        246,   0],\n","       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n","         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n","        225,   0],\n","       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n","        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n","        229,  29],\n","       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n","        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n","        230,  67],\n","       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n","        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n","        206, 115],\n","       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n","        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n","        210,  92],\n","       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n","        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n","        170,   0],\n","       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n","        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)</pre></div><script>\n","      (() => {\n","      const titles = ['show data', 'hide data'];\n","      let index = 0\n","      document.querySelector('#id-3003581c-80d9-484c-a68c-701e01b6a3e7 button').onclick = (e) => {\n","        document.querySelector('#id-3003581c-80d9-484c-a68c-701e01b6a3e7').classList.toggle('show_array');\n","        index = (++index) % 2;\n","        document.querySelector('#id-3003581c-80d9-484c-a68c-701e01b6a3e7 button').textContent = titles[index];\n","        e.preventDefault();\n","        e.stopPropagation();\n","      }\n","      })();\n","    </script>"],"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n","          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n","          1,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n","          0,   3],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n","          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n","         10,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n","         72,  15],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n","         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n","        172,  66],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n","        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n","        229,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n","        173,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n","        202,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n","        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n","        209,  52],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n","        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n","        167,  56],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n","        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n","         92,   0],\n","       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n","        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n","         77,   0],\n","       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n","        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n","        159,   0],\n","       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n","        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n","        215,   0],\n","       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n","        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n","        246,   0],\n","       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n","         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n","        225,   0],\n","       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n","        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n","        229,  29],\n","       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n","        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n","        230,  67],\n","       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n","        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n","        206, 115],\n","       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n","        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n","        210,  92],\n","       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n","        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n","        170,   0],\n","       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n","        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_images[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":114},"executionInfo":{"elapsed":433,"status":"ok","timestamp":1722990206856,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"i6TCByqqMkvL","outputId":"c5c0f462-5098-4aae-c890-46054a6899c1"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 100x100 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["train_images[0].shape\n","\n","import matplotlib.pyplot as plt\n","\n","image_data = train_images[0]\n","\n","plt.figure(figsize=(1,1))\n","plt.imshow(image_data, cmap='gray')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27636,"status":"ok","timestamp":1722991094786,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"gio8CORXOChZ","outputId":"8f7da0a7-1bf1-49c6-ac0b-8d207ff48f13"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.5908\n","Epoch 2/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.3559\n","Epoch 3/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.3204\n","Epoch 4/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.2951\n","Epoch 5/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2771\n","Epoch 6/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.2627\n","Epoch 7/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2487\n","Epoch 8/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2332\n","Epoch 9/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2264\n","Epoch 10/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2144\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3349\n","Test accuracy: 0.8885999917984009\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Fashion MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# 이미지 데이터를 0과 1사이의 값으로 정규화\n","train_images = train_images / 255.0\n","test_images = test_images /255.0\n","\n","# 이미지 데이터를 1D 벡터로 변환\n","train_images = train_images.reshape((-1,28*28))\n","test_images = test_images.reshape((-1,28*28))\n","\n","# 레이블을 원-핫인코딩\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","\n","model = models.Sequential([\n","    # 입력 계층 및 첫번 째 Dense 계층\n","    layers.InputLayer(input_shape=(28*28,)),\n","    layers.Dense(512, activation='relu'),\n","    # 두번째 Dense 계층\n","    layers.Dense(256, activation='relu'),\n","    # 출력계층 10개의 클래스 출력\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","\n","# # 모델 정의\n","# model = models.Sequential()\n","\n","# # 입력 계층 및 첫 번째 Dense 계층\n","# model.add(layers.InputLayer(shape=(28*28,)))\n","# model.add(layers.Dense(512, activation='relu'))\n","# # 두번째 계층\n","# model.add(layers.Dense(256, activation='relu'))\n","# # 출력 계층\n","# model.add(layers.Dense(10, activation='softmax')) # 10개의 클래스 출력\n","\n","model.compile(optimizer ='adam',\n","              loss = 'categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=10, batch_size=64)\n","\n","test_loss, test_acc = model.evaluate(test_images,test_labels)\n","print(f\"Test accuracy: {test_acc}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38152,"status":"ok","timestamp":1722991477203,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"MXW-RsFmR6XE","outputId":"ab4d4006-979f-430e-e823-b4f16aabd635"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.7216\n","Epoch 2/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8765 - loss: 0.3434\n","Epoch 3/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2953\n","Epoch 4/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.2611\n","Epoch 5/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.2358\n","Epoch 6/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2138\n","Epoch 7/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1924\n","Epoch 8/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1695\n","Epoch 9/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1594\n","Epoch 10/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.1540\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2599\n","Test accuracy: 0.9144999980926514\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Fashion MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# 이미지 데이터를 0과 1사이의 값으로 정규화\n","train_images = train_images / 255.0\n","test_images = test_images /255.0\n","\n","\n","# 레이블을 원-핫인코딩\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","# 이미지 차원 변경(모델에 맞게 차원 추가)\n","train_images = train_images.reshape((60000,28,28,1))\n","test_images = test_images.reshape((10000,28,28,1))\n","\n","model = models.Sequential([\n","    # 컨볼루션 레이어 추가\n","    layers.InputLayer(input_shape=(28,28,1)),\n","    layers.Conv2D(32,(3,3), activation='relu'),\n","    layers.MaxPooling2D((2,2)),\n","    layers.Conv2D(64, (3,3),activation='relu'),\n","    layers.MaxPooling2D((2,2)),\n","    # Dense 레이어 추가\n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'),\n","    # 출력계층 10개의 클래스 출력\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","\n","# # 모델 정의\n","# model = models.Sequential()\n","\n","# # 입력 계층 및 첫 번째 Dense 계층\n","# model.add(layers.InputLayer(shape=(28*28,)))\n","# model.add(layers.Dense(512, activation='relu'))\n","# # 두번째 계층\n","# model.add(layers.Dense(256, activation='relu'))\n","# # 출력 계층\n","# model.add(layers.Dense(10, activation='softmax')) # 10개의 클래스 출력\n","\n","model.compile(optimizer ='adam',\n","              loss = 'categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=10, batch_size=64)\n","\n","test_loss, test_acc = model.evaluate(test_images,test_labels)\n","print(f\"Test accuracy: {test_acc}\")"]},{"cell_type":"markdown","metadata":{"id":"kTy_8-UoYYUJ"},"source":["함수형 API\n","\n","Keras 내장 데이터셋인 Fashion MNIST를 사용하여 분류 모델을 학습하고 평가하세요.\n","- Fashion MNIST는 기존의 MNIST 데이터셋과 같은 형식을 가지고 있지만, 손으로 쓴 숫자 대신에 10가지 범주의 패션 아이템(예: 티셔츠, 바지, 신발 등)의 이미지로 구성\n","- 입력층, 두 개의 은닉층, 그리고 Softmax 활성화 함수를 사용하는 출력층으로 구성\n","- 모델은 Adam 최적화 알고리즘과 categorical_crossentropy 손실 함수를 사용하여 컴파일\n","- 학습 과정에서 정확도를 평가 지표로 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":663,"status":"ok","timestamp":1722993711966,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"Kg_BFpNjbW-0","outputId":"a92c3077-4590-4274-b821-2e20d53e23a4"},"outputs":[{"data":{"text/plain":["76.53061224489795"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["60000 / (28*28)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":694},"executionInfo":{"elapsed":17960,"status":"ok","timestamp":1722993668752,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"EuOatbhnTGf4","outputId":"a247d90c-e8b5-4db9-9011-851ad28f1de9"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_19\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.6690 - val_accuracy: 0.8569 - val_loss: 0.3881\n","Epoch 2/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3757 - val_accuracy: 0.8678 - val_loss: 0.3645\n","Epoch 3/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.3248 - val_accuracy: 0.8763 - val_loss: 0.3430\n","Epoch 4/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2983 - val_accuracy: 0.8774 - val_loss: 0.3356\n","Epoch 5/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2834 - val_accuracy: 0.8863 - val_loss: 0.3162\n","Epoch 6/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2670 - val_accuracy: 0.8854 - val_loss: 0.3086\n","Epoch 7/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.2480 - val_accuracy: 0.8858 - val_loss: 0.3234\n","Epoch 8/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2360 - val_accuracy: 0.8849 - val_loss: 0.3177\n","Epoch 9/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2297 - val_accuracy: 0.8845 - val_loss: 0.3239\n","Epoch 10/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2122 - val_accuracy: 0.8909 - val_loss: 0.3210\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3373\n","\n","테스트 손실: 0.3503016233444214\n","테스트 정확도: 0.8837000131607056\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images,test_labels) = fashion_mnist.load_data()\n","\n","# 데이터 전처리\n","# 이미지를 0-1 범위로 스케일링\n","# 60000 현재 이미지의 수 28*28 픽셀의 값\n","train_images = train_images.reshape((60000,28*28)).astype('float32') / 255\n","test_images = test_images.reshape((10000,28*28)).astype('float32') / 255\n","\n","# 레이블을 원 핫 인코딩\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","# 입력층 정의\n","input_shape = (784,)\n","input_layer = Input(shape=input_shape, name='input_layer')\n","\n","# 완전연결층 추가\n","hidden1 = Dense(512, activation='relu', name='hidden_layer_1')(input_layer)\n","hidden2 = Dense(256, activation='relu', name='hidden_layer_2')(hidden1)\n","\n","output_layer = Dense(10,activation='softmax',name='output_layer')(hidden2)\n","\n","# 모델 정의\n","model= Model(inputs=input_layer, outputs=output_layer)\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","# 모델 요약 출력\n","model.summary()\n","\n","# 모델 학습\n","model.fit(train_images,train_labels, epochs=10, batch_size=128, validation_split=0.2)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","\n","print('\\n테스트 손실:', test_loss)\n","print('테스트 정확도:',test_acc)"]},{"cell_type":"markdown","metadata":{"id":"QAg-RFRKbws-"},"source":["Q. MNIST 데이터셋에 대하여 함수형 API를 사용하여 같은 아키텍처의 신경망을 구성하여 학습 및 평가를 수행하세요.\n","- 입력층 : shape=(28, 28)\n","- 은닉층 1 : 128, relu\n","- 은닉층 2 : 64, relu\n","- 출력층 : 10, softmax\n","- 비용함수 : sparse_categorical_crossentro"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18520,"status":"ok","timestamp":1722995713939,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"AWEZO9JGbwMw","outputId":"202c96af-227a-40bc-99fd-9a599fa2acb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8119 - loss: 0.6648 - val_accuracy: 0.9479 - val_loss: 0.1828\n","Epoch 2/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.1579 - val_accuracy: 0.9611 - val_loss: 0.1294\n","Epoch 3/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.1126 - val_accuracy: 0.9672 - val_loss: 0.1138\n","Epoch 4/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0785 - val_accuracy: 0.9678 - val_loss: 0.1120\n","Epoch 5/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0597 - val_accuracy: 0.9713 - val_loss: 0.0996\n","Epoch 6/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0471 - val_accuracy: 0.9724 - val_loss: 0.0952\n","Epoch 7/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0378 - val_accuracy: 0.9718 - val_loss: 0.0959\n","Epoch 8/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0325 - val_accuracy: 0.9734 - val_loss: 0.0865\n","Epoch 9/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0247 - val_accuracy: 0.9737 - val_loss: 0.0911\n","Epoch 10/10\n","\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0185 - val_accuracy: 0.9746 - val_loss: 0.0942\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0978\n","\n","테스트 손실: 0.0852808877825737\n","테스트 정확도: 0.9758999943733215\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n","\n","# 전처리\n","train_images = train_images / 255.0\n","test_images = test_images / 255.0\n","\n","\n","input_shape = (28,28)\n","input_layer = Input(shape=input_shape, name='input_layer')\n","x = Flatten()(input_layer)\n","\n","hidden1 = Dense(128,activation='relu', name='hidden_layer_1')(x)\n","hidden2 = Dense(64, activation='relu',name='hidden_layer_2')(hidden1)\n","\n","output_layer = Dense(10, activation='softmax',name='output_layer')(hidden2)\n","\n","model = Model(inputs=input_layer, outputs=output_layer)\n","\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images,train_labels,epochs=10, batch_size=128, validation_split=0.2)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","\n","print('\\n테스트 손실:', test_loss)\n","print('테스트 정확도:',test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1722995717572,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"PoJvMS-PhPsp","outputId":"595d38f5-d8a3-4bca-90f4-4bd114e216d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n","Predicted class: 7\n"]}],"source":["import numpy as np\n","\n","# 새로운 이미지 데이터 예시(여기선느 실제 새로운 이미지 대신 테스트 이미지 중 하나를 사용)\n","# 실제 사용 시에는 새로운 이미지 데이터를 여기에 로드하고 전처리해야 합니다\n","# 예를 들어, 새로운 이미지가 하나만 있는 경우, 이미지를 (28,28)형태로 리사이징하고 정규화해야 합니다\n","new_image = test_images[0] # 실제로는 새로운 이미지 데이터를 사용해야 합니다\n","# [배치 크기, 이미지 높이, 이미지 너비, 채널 수]\n","new_image = np.expand_dims(new_image,axis=0) # 모델 입력을 위해 배치 차원 추가 (28,28)에서 (1,28,28)\n","\n","\n","predictions = model.predict(new_image)\n","\n","prediced_class = np.argmax(predictions,axis=1)\n","print(\"Predicted class:\", prediced_class[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1722996393725,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"OJToX-K5lj-9","outputId":"10b09356-cc4d-4f02-8d11-beed87ba406c"},"outputs":[{"data":{"text/plain":["(28, 28)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["test_images[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":477,"status":"ok","timestamp":1722996402155,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"5tXIXXevlpGO","outputId":"dc7a4009-a2b1-4f29-f285-dda1eca11f0d"},"outputs":[{"data":{"text/plain":["(1, 28, 28)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["new_image.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":114},"executionInfo":{"elapsed":1065,"status":"ok","timestamp":1722996367453,"user":{"displayName":"윤경","userId":"08475145638068530881"},"user_tz":-540},"id":"MYAF0tF7jFnD","outputId":"b4f883b1-67bf-4e53-c3b4-8d4b34c79525"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 100x100 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","image_data = test_images[0]\n","\n","plt.figure(figsize=(1,1))\n","plt.imshow(image_data, cmap='gray')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kjK-Q0IgmDQX"},"source":["Task1_0807. MNIST 데이터셋에 대해서 함수형 API로 아래와 같이 ConvNet 레이어를 추가하여 모델을 구성하고 학습 및 평가를 수행하세요.\n","\n","- ConvNet은 Conv2D 3개, MaxPooling2D 2개로 구성.\n","- 필터개수는 32, 64, 64개로 필터사이즈는 (3,3),\n","- Maxpooling2D의 윈도우 크기는 (2,2)\n","- 활성화 함수는  relu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6yWSxy5mDpe"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist\n","\n","(train_images,train_labels), (test_images,test_labels) = mnist.load_data()\n","\n","train_images = train_images / 255\n","test_images = test_images /255\n","\n","input_shape = (784,)\n","input_layer = Input(shape=input_shape, name='input_layer')\n","\n","hidden1 = Conv2D(32,(3,3),activation='relu',name='hidden_layer_1')(input_layer)\n","hidden2 = Conv2D(64,(3,3), activation='relu',name='hidden_layer_2')(hidden1)\n","hidden3 = Conv2D(64,(3,3),activation='relu',name='hidden_layer_3')(hidden2)\n","\n","hidden4 = MaxPooling2D((2,2))(hidden3)\n","hidden5 = MaxPooling2D((2,2))(hidden4)\n","\n","output_layer ="]},{"cell_type":"markdown","metadata":{"id":"WCkOg3RamkV8"},"source":["[ 선형 회귀 활성화 함수 ]\n","- 선형 회귀 모델의 출력 레이어는 보통 단일 뉴런으로 구성되며 활성화 함수가 없는  형태를 취하며 이는 모델이 어떠한 범위의 값을 직접 출력할 수 있게 하기 위함이다.\n","- 활성화 함수는 신경망에서 비선형성을 도입하기 위해 사용. 비선형 활성화 함수(예: ReLU, 시그모이드, 탄젠트 등)를 사용하면 신경망은 복잡한 패턴과 비선형 관계를 학습할 수 있다. 그러나 선형 회귀에서는 모델 출력이 입력 변수의 선형 조합으로 표현되어야 하므로, 비선형 활성화 함수를 사용할 필요가 없다.\n","- 따라서 선형 회귀 모델의 경우, 출력 계층에 \"linear\" 활성화 함수를 명시적으로 설정하거나 (이는 입력에 대한 아무런 변환도 적용하지 않는 것과 동일), 아예 활성화 함수를 지정하지 않는 것이 일반적. Keras에서 Dense 계층을 추가할 때 activation 매개변수를 설정하지 않으면 기본적으로 \"linear\" 활성화 함수가 사용된다. 즉, 출력 뉴런의 값은 입력에 대한 선형 변환 결과이다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQwACseXmk7L","executionInfo":{"status":"ok","timestamp":1722997488610,"user_tz":-540,"elapsed":8894,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"a48ded94-3f8d-45d2-e7ad-f4db38b3ede6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - loss: 8879.8086\n","Epoch 2/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 2134.0947\n","Epoch 3/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1137.9902\n","Epoch 4/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 986.3944\n","Epoch 5/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 958.8699\n","Epoch 6/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 949.6025\n","Epoch 7/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 943.0504\n","Epoch 8/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 936.9306\n","Epoch 9/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 930.9078\n","Epoch 10/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 924.9325\n","Epoch 11/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 918.9972\n","Epoch 12/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 913.1003\n","Epoch 13/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 907.2417\n","Epoch 14/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 901.4209\n","Epoch 15/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 895.6381\n","Epoch 16/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 889.8926\n","Epoch 17/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 884.1841\n","Epoch 18/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 878.5128\n","Epoch 19/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 872.8782\n","Epoch 20/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 867.2800\n","Epoch 21/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 861.7181\n","Epoch 22/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 856.1923\n","Epoch 23/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 850.7021\n","Epoch 24/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 845.2476\n","Epoch 25/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 839.8281\n","Epoch 26/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 834.4441\n","Epoch 27/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 829.0949\n","Epoch 28/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 823.7802\n","Epoch 29/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 818.5000\n","Epoch 30/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 813.2539\n","Epoch 31/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 808.0417\n","Epoch 32/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 802.8635\n","Epoch 33/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 797.7186\n","Epoch 34/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 792.6072\n","Epoch 35/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 787.5287\n","Epoch 36/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 782.4830\n","Epoch 37/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 777.4703\n","Epoch 38/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 772.4899\n","Epoch 39/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 767.5418\n","Epoch 40/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 762.6257\n","Epoch 41/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 757.7413\n","Epoch 42/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 752.8888\n","Epoch 43/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 748.0676\n","Epoch 44/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 743.2776\n","Epoch 45/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 738.5186\n","Epoch 46/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 733.7904\n","Epoch 47/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 729.0928\n","Epoch 48/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 724.4257\n","Epoch 49/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 719.7888\n","Epoch 50/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 715.1818\n","Epoch 51/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 710.6047\n","Epoch 52/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 706.0574\n","Epoch 53/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 701.5394\n","Epoch 54/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 697.0507\n","Epoch 55/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 692.5909\n","Epoch 56/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 688.1602\n","Epoch 57/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 683.7581\n","Epoch 58/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 679.3844\n","Epoch 59/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 675.0392\n","Epoch 60/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 670.7220\n","Epoch 61/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 666.4328\n","Epoch 62/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 662.1713\n","Epoch 63/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 657.9376\n","Epoch 64/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 653.7311\n","Epoch 65/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 649.5520\n","Epoch 66/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 645.3998\n","Epoch 67/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 641.2747\n","Epoch 68/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 637.1760\n","Epoch 69/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 633.1041\n","Epoch 70/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 629.0585\n","Epoch 71/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 625.0390\n","Epoch 72/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 621.0457\n","Epoch 73/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 617.0781\n","Epoch 74/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 613.1363\n","Epoch 75/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 609.2199\n","Epoch 76/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 605.3291\n","Epoch 77/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 601.4633\n","Epoch 78/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 597.6225\n","Epoch 79/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 593.8066\n","Epoch 80/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 590.0154\n","Epoch 81/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 586.2488\n","Epoch 82/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 582.5065\n","Epoch 83/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 578.7886\n","Epoch 84/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 575.0947\n","Epoch 85/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 571.4246\n","Epoch 86/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 567.7785\n","Epoch 87/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 564.1559\n","Epoch 88/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 560.5566\n","Epoch 89/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 556.9807\n","Epoch 90/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 553.4280\n","Epoch 91/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 549.8983\n","Epoch 92/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 546.3915\n","Epoch 93/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 542.9073\n","Epoch 94/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 539.4457\n","Epoch 95/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 536.0065\n","Epoch 96/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 532.5896\n","Epoch 97/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 529.1949\n","Epoch 98/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 525.8220\n","Epoch 99/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 522.4711\n","Epoch 100/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 519.1419\n","Epoch 101/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 515.8341\n","Epoch 102/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 512.5477\n","Epoch 103/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 509.2827\n","Epoch 104/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 506.0389\n","Epoch 105/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 502.8160\n","Epoch 106/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 499.6140\n","Epoch 107/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 496.4327\n","Epoch 108/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 493.2722\n","Epoch 109/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 490.1319\n","Epoch 110/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 487.0120\n","Epoch 111/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 483.9124\n","Epoch 112/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 480.8328\n","Epoch 113/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 477.7732\n","Epoch 114/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 474.7332\n","Epoch 115/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 471.7131\n","Epoch 116/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 468.7125\n","Epoch 117/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 465.7313\n","Epoch 118/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 462.7694\n","Epoch 119/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 459.8267\n","Epoch 120/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 456.9031\n","Epoch 121/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 453.9984\n","Epoch 122/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 451.1125\n","Epoch 123/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 448.2454\n","Epoch 124/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 445.3966\n","Epoch 125/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 442.5664\n","Epoch 126/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 439.7546\n","Epoch 127/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 436.9609\n","Epoch 128/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 434.1853\n","Epoch 129/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 431.4277\n","Epoch 130/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 428.6879\n","Epoch 131/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 425.9659\n","Epoch 132/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 423.2615\n","Epoch 133/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 420.5745\n","Epoch 134/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 417.9051\n","Epoch 135/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 415.2529\n","Epoch 136/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 412.6179\n","Epoch 137/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 409.9999\n","Epoch 138/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 407.3988\n","Epoch 139/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 404.8148\n","Epoch 140/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 402.2473\n","Epoch 141/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 399.6965\n","Epoch 142/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 397.1621\n","Epoch 143/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 394.6442\n","Epoch 144/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 392.1427\n","Epoch 145/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 389.6573\n","Epoch 146/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 387.1880\n","Epoch 147/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 384.7346\n","Epoch 148/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 382.2972\n","Epoch 149/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 379.8756\n","Epoch 150/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 377.4696\n","Epoch 151/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 375.0793\n","Epoch 152/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 372.7043\n","Epoch 153/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 370.3448\n","Epoch 154/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 368.0005\n","Epoch 155/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 365.6715\n","Epoch 156/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 363.3575\n","Epoch 157/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 361.0585\n","Epoch 158/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 358.7744\n","Epoch 159/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 356.5050\n","Epoch 160/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 354.2503\n","Epoch 161/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 352.0104\n","Epoch 162/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 349.7849\n","Epoch 163/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 347.5738\n","Epoch 164/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 345.3769\n","Epoch 165/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 343.1943\n","Epoch 166/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 341.0259\n","Epoch 167/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 338.8715\n","Epoch 168/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 336.7310\n","Epoch 169/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 334.6044\n","Epoch 170/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 332.4916\n","Epoch 171/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 330.3924\n","Epoch 172/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 328.3069\n","Epoch 173/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 326.2348\n","Epoch 174/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 324.1762\n","Epoch 175/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 322.1309\n","Epoch 176/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 320.0988\n","Epoch 177/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 318.0799\n","Epoch 178/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 316.0741\n","Epoch 179/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 314.0813\n","Epoch 180/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 312.1013\n","Epoch 181/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 310.1341\n","Epoch 182/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 308.1797\n","Epoch 183/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 306.2380\n","Epoch 184/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 304.3087\n","Epoch 185/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 302.3922\n","Epoch 186/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 300.4879\n","Epoch 187/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 298.5961\n","Epoch 188/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 296.7163\n","Epoch 189/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 294.8488\n","Epoch 190/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 292.9933\n","Epoch 191/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 291.1500\n","Epoch 192/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 289.3186\n","Epoch 193/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 287.4990\n","Epoch 194/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 285.6911\n","Epoch 195/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 283.8951\n","Epoch 196/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 282.1106\n","Epoch 197/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 280.3377\n","Epoch 198/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 278.5761\n","Epoch 199/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 276.8261\n","Epoch 200/200\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 275.0873\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7bc1d9f27400>"]},"metadata":{},"execution_count":41}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","x = np.array([2,4,6,8])\n","y = np.array([81,93,91,97])\n","\n","model = Sequential()\n","\n","# 출력 값, 입력 변수, 분석 방법에 맞게끔 모델 설정\n","# model.add(Dense(1, input_dim=1, activation='linear'))\n","# model.add(Dense(1,input_dim=1))\n","\n","model.add(Input(shape=(1,)))\n","model.add(Dense(1))\n","\n","# 오차 수정을 위해 경사 하강법(sgd)을, 오차의 정도를 판단하기 위해 평균 제곱 오차(mse)를 사용함\n","model.compile(optimizer='sgd', loss='mse')\n","\n","# 오차를 최소화하는 과정을 2000번 반복\n","model.fit(x,y,epochs=200)"]},{"cell_type":"code","source":["plt.scatter(x,y)\n","plt.plot(x,model.predict(x),'r')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"0siUh5wlqdBo","executionInfo":{"status":"ok","timestamp":1722997688935,"user_tz":-540,"elapsed":751,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"ff78a658-ea93-489b-eebc-91431262a29c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","\n","hour = 7\n","\n","prediction = model.predict(np.array([hour]).reshape(-1,1))\n","\n","print(\"%.f시간을 공부할 경우의 예상 점수는 %.02f점입니다\") % (hour, prediction[0][0])"],"metadata":{"id":"MivJQXRcySA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.models import Sequential\n","\n"],"metadata":{"id":"1lnJYvCG5CSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","\n","df = pd.read_csv('')"],"metadata":{"id":"482zrLLh5_om"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPapeW2P8sTT9dtiT3V5hFv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}