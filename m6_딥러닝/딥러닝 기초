< 신경망에서 가중치를 업데이트하는 기본적인 과정 >

1. 초기 가중치 설정: 신경망의 가중치는 보통 랜덤하게 초기화
이는 학습이 시작될 때 모든 가중치가 비슷한 값을 가지면 네트워크가 같은 방향으로 업데이트되기 때문


2. 활성화 함수: 입력값이 가중치와 곱해진 후 활성화 함수에 의해 변환
활성화 함수는 뉴런의 출력 값을 결정하는데, 대표적으로 Sigmoid, ReLU, Tanh 등이 있음


3. 손실 함수: 활성화 함수의 출력은 네트워크의 예측값이 되며,
실제값과의 차이를 계산하는데 손실 함수가 사용
손실 함수는 모델의 예측이 실제값과 얼마나 차이가 있는지를 측정
대표적인 손실 함수로는 Mean Squared Error (MSE)와 Cross-Entropy Loss가 있음


4. 역전파 (Backpropagation): 손실 함수에서 계산된 오차를 네트워크를 거꾸로 전파하여 
각 가중치가 손실에 미치는 영향을 계산
이 과정에서 오차의 기울기(gradient)를 계산하여, 각 가중치가 얼마나 조정되어야 하는지를 알아냄


5. 가중치 업데이트: 계산된 기울기를 기반으로 가중치를 업데이트
이 때 사용되는 방법이 경량화(optimization) 알고리즘으로,
가장 대표적인 방법이 경사 하강법(Gradient Descent)
이 과정에서 학습률(learning rate)이라는 하이퍼파라미터를 사용하여 가중치를 조정


이 과정을 여러 번 반복하면서 네트워크의 가중치는 점점 더 최적화되어 가며,
손실 함수의 값이 줄어들어 모델의 예측 성능이 향상


====================================================================================

딥러닝 모델들은 신경망 알고리즘을 공통적으로 사용
-> 주로 네트워크의 구성(구조, 레이어 수, 활성화 함수, 연결 방식 등)에 따라 차이

딥러닝 모델의 핵심요소

- 학습 알고리즘: 대부분의 딥러닝 모델들은 역전파(Backpropagation) 알고리즘과 경사 하강법(Gradient Descent)을 사용하여 가중치를 업데이트하고 학습
이 방법을 통해 신경망은 입력 데이터에 대한 오류(손실 함수)를 계산하고,
이 오류를 줄이기 위해 가중치와 편향을 조정


- 손실 함수: 딥러닝 모델은 학습 과정에서 손실 함수(Loss Function)를 최소화하려고 함
이 손실 함수는 모델의 예측 값과 실제 값의 차이를 측정하며, 모델의 성능을 평가하는 중요한 지표


- 활성화 함수: 모든 신경망 모델은 선형 변환 이후 활성화 함수를 적용하여 비선형성을 도입하고,
이를 통해 복잡한 패턴을 학습할 수 있음







