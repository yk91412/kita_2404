
** 통계 활용

   - 표준 편차가 10보다 크면 변동성이 큰 편(도메인 지식 활용)

   - 이상값 확인 : 사분위수 활용

            q3-q1 = iqr

            q1 - 1.5 * iqr보다 작거나 q3 + 1.5 *iqr보다 클 때

    - 상관계수가 0.7보다 크면 상관관계가 큰 편

    - np.unique : 중복 요소 제거

    - np.unique(return_counts=True) : 각 고유한 요소가 나타나는 횟수를 보여줌




======================================================================

- 통계 분석

    인과관계를 중요시 

    => 명확한 가정(정규성, 독립성, 등분산성)에 기반하고, 이 가정들은 모델의 유효성을 판단하는데 중요


    데이터로부터 모델을 만들어 현상을 설명하고 이해하는데 중점

    통계분석의 결과는 데이터에 대한 해석과 추론에 중점


- 기계 학습

    예측 성능을 중요시

    => 해석 가능성 보다는 예측 선응이 더 중요한 역할

        때로 해석하기 어려울 수 있으며 "블랙 박스"로 간주

    데이터로부터 패턴을 학습하여 미래 데이터에 대한 예측을 하는데 중점

    기계학습의 결과는 주로 예측의 정확도와 모델의 성능에 중점


======================================================================


  - 통계적 기법


  1. 기초 통계

    * 기술 통계 : 데이터의 기본적인 특성을 요약하고 설명

                  ex) 평균, 중앙값, 표준편차, 분산, 사분위수 ...


    * 추론 통계 : 표본 데이터를 이용해 모집단에 대한 결론 도출


                ex) 가설 검정, 신뢰 구간, p-value ..



  2. 확률 이론

    * 확률 분포 : 데이터가 어떤 패턴을 따르는지 설명

                  ex) 정규분포, 이항분포, 포아송분포 ...


    * 확률 변수 : 결과가 확률에 따라 결정되는 변수

                  ex) 이산 확률 변수, 연속 확률 변수


    * 기대값과 분산 : 확률 변수의 평균과 변동성을 측정




  3. 가설 검정

    귀무가설과 대립가설 : 검정의 기본 가정. 귀무가설은 보통 '효과 없음'을 가정

    t-검정 : 두 그룹의 평균을 비교하는 데 사용

    카이제곱 검정 : 범주형 데이터의 분포를 비교

    ANOVA: 세 개 이상의 그룹 간의 평균 차이를 비교



  4. 회귀 분석


    * 단순 선형 회귀 : 하나의 독립 변수와 종속 변수 간의 관계를 모델링


    * 다중 선형 회귀 : 여러 독립 변수와 종속 변수 간의 관계를 모델링


    * 로지스틱 회귀 : 종속 변수와 범주형일 때 사용
            



  5. 확률 모델링

    베이지안 통계 : 사전 지식과 데이터를 결합하여 결론을 도출



  6. 시간 시계열 분석

    추세 분석 : 데이터의 장기적인 증가 또는 감소 경향을 파악

    계절성 분석 : 데이터의 주기적인 패턴을 분석

    ARIMA 모델 : 시간 시계열 데이터를 분석하고 예측하는 데 사용



7. 고급 통계 기법

    * 주성분 분석 (PCA) : 고차원의 데이터를 저차원으로 축소하여 중요한 패턴을 찾는다

    * 클러스터링 : 데이터 포인트를 유사한 그룹으로 나눈다

                  K-평균, 계층적 클러스터링 등이 포함



===============================================================

  - 기초 통계



    ** 평균과 표준편차

        데이터의 중심 경향성과 분산을 파악하는 데 유용

            ex) 학생들의 시험 점수 데이터를 분석할 때

                평균과 표준편차를 통해 전체 성적 수준과 변동성을 이해할 수 있다



    ** 중간값과 사분위수

        데이터의 중심 경향과 분포를 이해하는 데 도움을 준다

          ex) 가계 소득 데이터를 분석할 때 중간값과 사분위수를 통해

                소득 분포를 파악할 수 있다


    ** 평균값과 중앙값

        1. 평균값 > 중앙값

          데이터는 오른쪽으로 치우친(오른쪽 꼬리가 긴) 분포
            => '오른쪽으로 치우친 분포' 또는 '양의 왜곡 분포'

          특징
          
          데이터의 높은 값(오른쪽 꼬리)에 이상치나 극단적인 높은 값들이 존재

          예시

            적은 수의 매우 높은 소득을 가진 사람들이 있는 소득 데이터

            => 극단적으로 높은 값들은 평균을 중앙값보다 더 높게 밀어올린다


      2. 중앙값 > 평균값

        데이터는 일반적으로 왼쪽으로 치우친(왼쪽 꼬리가 긴) 분포

        => 분포를 '왼쪽으로 치우친 분포' 또는 '음의 왜곡 분포'

        특징
        
        데이터의 낮은 값(왼쪽 꼬리)에 이상치나 극단적인 낮은 값들이 존재
        
        예시

        적은 수의 매우 낮은 소득을 가진 사람들이 있는 소득 데이터

        이러한 극단적으로 낮은 값들은 평균을 중앙값보다 더 낮게 끌어내린다


        ** 중요성
        
        평균과 중앙값 사이의 차이는 데이터의 비대칭성을 나타내며 이 차이가 클수록 데이터 분포의 왜곡이 더 크다고 볼 수 있다

        데이터 분석에서는 이러한 왜곡을 인지하고 적절한 해석과 분석 방법을 선택하는 것이 중요
        
        ex) 이상치나 극단적인 값이 데이터의 해석에 큰 영향을 미칠 수 있으므로, 이를 고려하여 분석을 진행



===============================================================

  - 상자 그림

    데이터의 분포와 이상치를 시각화하는 데 유용
    
    ex) 회사의 연봉 데이터를 분석할 때 상자 그림을 통해 연봉의 분포와 이상치를 파악
    
    
    ** 의미와 중요성

        이상치의 영향

        평균값은 이상치에 의해 크게 왜곡될 수 있다

        ex) 소득 데이터에서 몇몇 매우 높은 값(억만장자의 소득)이 평균을 크게 올릴 수 있지만

            중앙값은 이러한 극단적인 값의 영향을 덜 받는다

    ** 데이터 분포의 대표성

        중앙값은 데이터의 분포가 비대칭일 때 데이터의 "중심"을 더 잘 나타내는 경향이 있다

        반면, 평균값은 데이터가 대칭적인 분포를 가질 때 중심 경향을 잘 나타낸다

    ** 데이터 해석

        데이터 분석에서는 종종 평균값과 중앙값을 함께 사용하여 데이터의 분포를 더 잘 이해한다
        
        두 척도 사이에 큰 차이가 있다면, 이는 데이터에 이상치나 극단적인 값이 있다는 신호일 수 있다
        
        따라서 평균값과 중앙값을 선택할 때는 데이터의 특성과 분석의 목적을 고려해야 하며
        
        이상치가 존재하거나 데이터가 비대칭적인 분포를 가질 경우, 중앙값이 더 적절할 수 있다
        
        반면, 데이터가 정규 분포를 이루는 경우, 평균값이 데이터를 대표하는 데 적합할 수 있다

===============================================================

    - numpy에서 사분위수 구하기

    np.percentile(data,(25 or 75))


    - np.random.normal

    평균, 표준편차를 지정하여 정규분포로부터 난수 생성

    => size 매개변수를 사용하여 크기 지정 가능

    ex) 평균 50, 표준편차 10인 정규분포에서 100개 샘플 생성

        -> np.random.normal(50,10,100)


===============================================================

  - 산점도

      두 변수 간의 관계를 시각화하는 데 유용

        ex) 광고비와 매출 데이터를 분석할 때 산점도를 통해

              광고비와 매출 간의 관계를 파악할 수 있다


        ** 추세선이 있는 산점도

        두 변수 간의 관계를 시각화하고, 추세선을 통해 데이터의 경향성을 파악하는 데 유용

        ex) 마케팅 캠페인 기간과 매출 데이터를 분석할 때

            추세선이 있는 산점도를 통해 캠페인 기간이 매출에 미치는 영향을 파악


            => ** np.polyfit

                    데이터 포인트들에 대해 다항식 회귀를 수행하는 함수

                    데이터 포인트들을 가장 잘 나타내는 다항식의 계수를 반환

                    ex) np.polyfit(x, y, deg)

                        x : 독립 변수의 값들을 포함하는 배열

                        y : 종속 변수의 값들을 포함하는 배열

                        deg : 회귀할 다항식의 차수


           ex) m, b = np.polyfit(x, y, deg)

            x와 y는 데이터 포인트의 x와 y 좌표를 나타내며

            m과 b는 단순 선형 회귀 모델에서의 기울기와 y 절편 나타냄


===============================================================

    - 상관 계수

    두 변수 간의 선형 관계를 측정하는 데 사용

    ex) 온도와 아이스크림 판매량 데이터를 분석할 때
    
    상관 계수를 통해 두 변수 간의 관계 강도를 파악할 수 있다

        pandas에서 상관계수 : corr()
        
        numpy에서 상관계수 : corrcoef()


===============================================================

    - 히트맵
    
    변수 간의 상관 관계를 시각화하는 데 유용

    ex) 여러 주식의 일일 수익률 데이터를 분석할 때 히트맵을 통해

    각 주식 간의 상관 관계를 시각화할 수 있다


    => sns.heatmap(data, annot=True, cmap = 'coolwarm')

===============================================================

    - 확률

      모든 가능한 사건들의 확률의합은 1

      (불가능한 사건 0, 확실한 사건 1)

    ** 확률 변수

      무작위 실험의 결과를 수치로 나타내는 변수

      ex) 이산형, 연속형

          주사위를 던질 때 나오는 눈의 수, 특정 시간 동안의 온도

    ** 확률 분포

      확률 변수가 취할 수 있는 값과 그 값이 나타날 확률

       * product(dice,repeat=2)
        
        dice리스트에서 2개의 요소를 뽑아 순서를 고려한 모든 가능한 조합 생성


      1) 이산형 확률변수

        => 확률 질량함수(PMF) : 각 값이 나타날 확률

      2) 연속형 확률 변수

        => 확률 밀도 함수(PDF) : 특정 구간 내에서 값이 나타날 확률

            ex) 동전을 10번 던질 때, 앞면이 정확히 6번 나올 확률

                from scipy.stats import binom

                binom.pmf(성공횟수,총 시행횟수,성공할 확률)

                즉. binom.pmf(6,10,0.5)

    
            누적 분포 함수(CDF) : 확률변수가 특정 값 이하일 확률


            ex) 정규분포를 따르는 데이터에서 평균이 0, 표준편차가 1일 때, 값이 1보다 작을 확률

                import scipy.stats as stats

                stats.norm.cdf(1,0,1(표준편차))


===============================================================

    - 기대값

        확률분포의 평균을 의미

        확률변수가 가질 수 있는 값들에 대한 확률 가중 평균

        ex) 주사위를 던질 때 나오는 수의 기대값

            values = [1,2,3,4,5,6]
            probabilities = [1/6] * 6  => 6분의 1이 6개의 있는 리스트 생성

            **기대값 계산

            sum(value * prob for value, prob in zip(values,probabilities))




===============================================================

    - 분산

      확률 변수가 평균으로부터 얼마나 떨어져 있는지 나타내는 지표

        확률분포의 흩어짐 정도를 나타내며, 기대값이 중심에 있을 때 개별 데이터가 얼마나 퍼져있는지 보여줌

        분산이 클수록 데이터가 평균값 주위에 널리 퍼져있고,

        작을수록 데이터가 평균값에 더 가깝게 모여있음


        ex) 점수와 점수의 확률이 정해져있을 때. 시험 점수의 분산을 계산

            score = [60,70,80,90,100]
            probability = [0.1,0.2,0.4,0.2,0.1]

        
        기대값 계산
        
        sum(value * prob for value, prob in zip(score,probability))
        
        분산 구하기
        
        sum((value-expected_value) ** 2 * prob for value, prob in zip(score, probability))


        *** 표준편차는 분산의 제곱근

            점수 - 기대값 => 표준편차 

            이를 제곱한 값은 분산
