{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0619"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0619. 다음 사항을 수행하세요.\n",
    "- 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "- 모든 'p' 태그 찾기\n",
    "- 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "- 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "- 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "- 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "- 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "- 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "- 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "- 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   Title\n",
      "  </h1>\n",
      "  <p class=\"content\">\n",
      "   First paragraph.\n",
      "  </p>\n",
      "  <p class=\"content\">\n",
      "   Second paragraph.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_content = '<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>'\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 매칭되는 p First paragraph.\n",
      "First paragraph.\n",
      "Second paragraph.\n"
     ]
    }
   ],
   "source": [
    "p_tag = soup.find('p')\n",
    "print(f\"첫번째 매칭되는 p {p_tag.get_text()}\")\n",
    "p_tags = soup.find_all('p')\n",
    "for p in p_tags:\n",
    "    print(p.get_text())\n",
    "c_tag = soup.find(class_ = 'content')\n",
    "print(f\"첫번째 매칭되는 클래스 {c_tag.text}\")\n",
    "c_tags = soup.find_all(class_ = 'content')\n",
    "for c in c_tags:\n",
    "    print(c.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p>\n",
      "첫번째 매칭되는 클래스 First paragraph.\n"
     ]
    }
   ],
   "source": [
    "# class가 content이면서 첫번째 p태그 찾기\n",
    "c_tag = soup.find('p',class_ = 'content')\n",
    "print(c_tag)\n",
    "print(f\"첫번째 매칭되는 클래스 {c_tag.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p> \n",
      "\n",
      "First paragraph.\n"
     ]
    }
   ],
   "source": [
    "# select 사용\n",
    "first_content_p = soup.select_one('p.content')\n",
    "print(first_content_p,'\\n')\n",
    "print(first_content_p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"content\">First paragraph.</p>, <p class=\"content\">Second paragraph.</p>]\n",
      "First paragraph.\n",
      "Second paragraph.\n"
     ]
    }
   ],
   "source": [
    "# p태그 이면서 class가 content인 태그\n",
    "all_content_p = soup.select('p.content')\n",
    "\n",
    "# p를 제외하고 클래스만 써도 추출이 가능하다\n",
    "# all_content_p = soup.select('.content')\n",
    "\n",
    "print(all_content_p)\n",
    "for p in all_content_p:\n",
    "    print(p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>] \n",
      "\n",
      "<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n",
      "body\n",
      "<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>\n",
      "html\n",
      "<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 p 태그의 모든 부모 태그 찾기\n",
    "# [document] > [html] > [body] > [p] : 최상위 요소 document에서 시작하여 p태그까지의 모든 부모 요소를 출력\n",
    "all_parents = p_tag.find_parents()\n",
    "print(all_parents,'\\n')\n",
    "for parent in all_parents:\n",
    "    print(parent)\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n",
      "1111 <body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n",
      "name :  body \n",
      "\n",
      "<p class=\"content\">Second paragraph.</p> \n",
      "\n",
      "p \n",
      "\n",
      "<h1>Title</h1> \n",
      "\n",
      "[<p class=\"content\">Second paragraph.</p>] \n",
      "\n",
      "[<h1>Title</h1>] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 p 태그의 첫번째 부모 태그 찾기\n",
    "first_parent = p_tag.find_parent()\n",
    "print(first_parent)\n",
    "f1 = c_tag.find_parent()\n",
    "print('1111',f1)\n",
    "print('name : ',f1.name,'\\n')\n",
    "\n",
    "# 첫번째 p 태그의 다음 형제 태그 찾기\n",
    "next_sli = p_tag.find_next_sibling()\n",
    "print(next_sli,'\\n')\n",
    "print(next_sli.name,'\\n')\n",
    "# 첫번째 p 태그의 이전 형제 태그 찾기\n",
    "pre_sli = p_tag.find_previous_sibling()\n",
    "print(pre_sli,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">Second paragraph.</p>\n"
     ]
    }
   ],
   "source": [
    "# 특정 p 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "next_elements = p_tag.find_next()\n",
    "print(next_elements)\n",
    "previous_elements = p_tag.find_previous()\n",
    "print(previous_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0619. ID를 이용해서 '네이버 뉴스' 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "s = soup.select_one('#browserTitleArea')\n",
    "s = soup.select_one('title#browserTitleArea')\n",
    "print(s.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title id=\"browserTitleArea\">네이버 뉴스</title>\n",
      "네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "title_element = soup.find('title',id='browserTitleArea')\n",
    "print(title_element)\n",
    "print(title_element.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0619. soup.find_all(class_='Nitem_link_menu') 대신에 select를 이용하여 동일한 결과를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 언론사별\n",
      "2 : 정치\n",
      "3 : 경제\n",
      "4 : 사회\n",
      "5 : 생활/문화\n",
      "6 : IT/과학\n",
      "7 : 세계\n",
      "8 : 랭킹\n",
      "9 : 신문보기\n",
      "10 : 오피니언\n",
      "11 : TV\n",
      "12 : 팩트체크\n",
      "13 : 알고리즘 안내\n",
      "14 : 정정보도 모음\n"
     ]
    }
   ],
   "source": [
    "items = soup.select('.Nitem_link_menu')\n",
    "for i, item in enumerate(items):\n",
    "    print(f\"{i+1} : {item.get_text().strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task4_0619. select_one을 이용해서 'https://news.naver.com'에서 \"뉴스\"를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스\n"
     ]
    }
   ],
   "source": [
    "news = soup.select_one('.Nicon_service')\n",
    "# news = soup.select_one('span.Nicon_service')\n",
    "print(news.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task5_0619.'https://news.naver.com'에서 아래 예시와 같이 뉴스 기사 제목을 모두 출력하세요. \n",
    "\n",
    "예시: 1: [속보] '훈련병 사망' 얼차려 지시 중대장·부중대장 피의자 신분 첫 소환조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 3억 로또 줍줍…이번엔 성남에 20만명 몰렸다\n",
      "2 : \"엉덩이 조금 때렸는데\"…경찰, 순창 '집단 폭행' 안일 대응 논란[영상]\n",
      "3 : 석유공사 사장 \"말하면 알만한 글로벌 기업과 추가 검증 마쳤다\"\n",
      "4 : [도초도 수국축제] 지금 만나러 갑니다 1004만 송이 수국\n",
      "5 : 속속 드러난 부실 대응... 지차체 공무원 10명 추가 기소\n",
      "6 : 실질 지원 기대감 “해봐야”…익명 출산 딜레마 “해봤자”\n",
      "7 : 은행 슈퍼앱, 디지털 헬스케어 품는다\n",
      "8 : 박세리 부친 입 열었다 \"아빠니까 나설 수 있다는 생각\"\n",
      "9 : 2025년 직장인 쉬는 날 119일…3일 이상 연휴 6번\n",
      "10 : 징역 9년 6개월 이화영 판결문 속 이재명\n",
      "11 : [단독]‘몰카 안경’ 쓰고 유치장-판사 몰래 찍은 30대 여성 구속기소\n",
      "12 : 푸틴, 또 김정은에게 ‘러시아판 롤스로이스’ 아우루스 선물\n",
      "13 : 지방선거까지 尹-韓 충돌 없다? '출마 임박' 韓 앞 '고차방정식'\n",
      "14 : 비대면 대출 해준다더니…돌아온 건 계좌 정지\n",
      "15 : 양육비 안 준 부모 164명, 출국금지·명단공개 등 제재\n",
      "16 : 오물 풍선 소동, 끝난 게 아니다\n",
      "17 : \"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손웅정 발언 재조명\n",
      "18 : “자식 돈에 어디 숟가락”…박세리 논란에 소환된 손웅정\n",
      "19 : \"버티다, 버티다 못해 가입했다\"…신규 요금제 이용 유도하는 배민[배달앱의배신]\n",
      "20 : 에코+페미, 우리 지금 만나\n",
      "21 : 현빈이 입은 '이 옷' 해외서도 난리…주가 58% 뛰었는데 \"더 뛴다\"\n",
      "22 : 김호중 음주운전 혐의 제외에…\"우리도 도망가자\" 공분\n",
      "23 : BBQ, '4000원 할인 쿠폰' 프로모션...민심 잡기 나선다\n",
      "24 : \"한쪽 침략당하면 상호지원\"…랍스터 먹고, 한밤 배웅까지\n",
      "25 : Summit of two loners: Kim breaks seclusion with Putin by his side\n",
      "26 : \"자식 돈에 어디 숟가락 얹나\"…박세리 논란에 손흥민父 재조명\n",
      "27 : 바지 벗고 길에 쪼그려 앉은 아이…제주 발칵 뒤집은 영상 [잇슈 키워드]\n",
      "28 : 이재명·한동훈 ‘단두대 매치’ 성사되나\n",
      "29 : ‘형만 믿어’…한반도 유사시 러시아 개입 길 열렸다 [뉴스+]\n",
      "30 : '갤럭시 A35' 국내 출시…\"엔터테인먼트 시청에 최적\"\n",
      "31 : 제로라니까 제로인 줄 알았어? '제로슈거'의 거짓말 [추적+]\n",
      "32 : 끝모를 쌀값 하락…“재고 15만t 신속 격리를”\n",
      "33 : 납품 전선 이상 無… 韓방산, 2분기 호실적 기대\n",
      "34 : \"몸이 갑자기 거인처럼 커진다\" 감각이 왜곡된다는 女, 무슨 증후군?\n",
      "35 : 푸틴, 24년만의 방북…21시간 머물고 김정은 배웅 속 평양 떠나\n",
      "36 : 푸틴, 21시간 방북 종료…김정은, 비행기 뜰 때까지 손 흔들어\n",
      "37 : 한국인이 가장 좋아하는 유튜버 1위는?\n",
      "38 : AI가 광고를 만든다? \"중요한 건 인간의 판단력\"\n",
      "39 : 종로 포차거리에서 흉기난동, 휴무 경찰이 제압\n",
      "40 : 영국 명소 스톤헨지에 환경단체 주황 물감 스프레이 분사\n",
      "41 : '채 해병 사건 회수' 시작점에 윤석열... 새 통화 기록 나왔다\n",
      "42 : 내년 추석은 7일 쉰다…주5일 직장인 휴일 '119일'\n",
      "43 : 서울 35도 ‘찜통더위’…제주 거센 장맛비\n",
      "44 : 백종원·곽튜브 제쳤다… 한국인이 좋아하는 유튜버 1위는?\n",
      "45 : 이스라엘군 대변인 \"하마스 궤멸, 사실상 불가능\"…공개 발언서 지도부 저격\n",
      "46 : \"음주운전하면 무조건 튀어라\"…'음주 혐의' 빠진 김호중에 뿔난 여론\n",
      "47 : 길거리서 용변 본 아이, 엄마는 나 몰라라.. \"몰상식 행위  처벌해야\"\n",
      "48 : [이사람] 영업이익 18조원 달성한 정의선 회장…국내 그룹 총수 중 '최고'\n",
      "49 : [단독] 영화숙·재생원 악몽, 국제사회에 첫 증언\n",
      "50 : \"李 민주당의 아버지\" 찬사에…진중권 \"아바이 수령, 이재명 주석 만세!\"\n",
      "51 : “귀엽지만 음식에 털 날려서…” 반려동물 식당 출입에 곳곳 갈등\n",
      "52 : \"영부인께 엿 3백만 원어치 선물해도 돼요?\" 권익위 답변은‥\n",
      "53 : 하늘에서 내려오는 ‘공짜’ 다이어트 보조제… 지금 실컷 누리자\n",
      "54 : [인사이드 스토리]반전 거듭하는 애플…아이폰 슈퍼사이클 맞을까\n",
      "55 : 백종원·김어준·임영웅의 '굴욕'…'이 여자'한테 다 밀렸다…한국인 최애 유튜버는 누구?\n",
      "56 : ‘미투’ 서지현 검사 근황 보니…“정치권, ‘이대남’ 표 위해 ‘女 지우기’ 급급”\n",
      "57 : 목동 아파트 화재 12시간 만에 진압…긴박했던 순간들\n",
      "58 : [아워홈 남매의난 시즌2] 구미현 신임 회장, 아워홈 경영권 매각 공식화했지만...매각까지 '산 넘어 산'\n",
      "59 : “시청률 0%, 터질게 터졌다” 넷플릭스발 초유의 사태 ‘발칵’\n",
      "60 : 尹 대통령 \"인구 국가비상사태\"…저출생 대책 드라이브 시동  \n",
      "61 : 이준석 \"어대한? 아니라고 봐…尹이 그냥 지나칠리가\" [정치쇼]\n",
      "62 : “비둘기, 멧돼지, 다람쥐 여러분…피임하세요” 과학자들 피임약 뿌려 개체수 조절 시험중\n",
      "63 : [인터뷰] “한국 넘버원 역직구 플랫폼 꿈꾸죠”…딜리버드코리아 직원들의 자신감\n",
      "64 : 권도형 구금 몬테네그로 총리, 알고 보니 ‘테라 초기 투자자’\n",
      "65 : 어제 ‘인구국가비상사태’ 보셨나요…‘진짜 비상사태’ 3가지 빠졌던데\n",
      "66 : \"이게 무슨 추태냐\"...'대구 공무원 치킨집 갑질' 탄식에 홍준표 한마디\n",
      "67 : 정용진 신세계 '신상필벌' 인사에 직원들 ‘긴장’\n",
      "68 : 민주당내 '이재명 아버지' 발언에 진중권 \"연호도 붙여줘라\"\n",
      "69 : 방문 요양보호사들 ‘임금 올려라’ 국가에 소송 제기\n",
      "70 : [단독] 놀이동산서 불법 촬영한 10대 학생 '덜미'\n",
      "71 : 미분양 빠지고 고가에 팔리고… 바닷가만 꿈틀\n",
      "72 : “한달에 3천만원 저축, 연봉 5~6억”…악착같이 모은다는 무명개그맨의 정체\n",
      "73 : \"재명2년\"…이재명 저격한 진중권, 무슨 뜻인가 봤더니\n",
      "74 : \"TV수신료 고지서 7월10일 도착한다\"\n",
      "75 : \"역대 가장 더운 6월\"..정읍 37.5도까지 치솟아\n",
      "76 : \"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손흥민 父 손웅정 발언 재조명\n",
      "77 : 정신질환으로 우발적 살인? '심신미약'이면 여성 살해해도 되나\n",
      "78 : 내년 추석 연휴는 1주일…개천절부터 한글날까지 쉰다\n",
      "79 : Putin, Kim sign strategic partnership as North backs Russia's war in Ukraine\n",
      "80 : 올해 장마 시작...제주 밤새 장맛비 내려\n",
      "81 : 북러, 포괄적 동반자 협정 체결 \"침략 당하면 상호지원\"\n",
      "82 : “푸틴 태우고 운전” 김정은 포착…선물받은 ‘아우루스’ 직접 몰았다\n"
     ]
    }
   ],
   "source": [
    "titles = soup.select('.cjs_t')\n",
    "for i, title in enumerate(titles):\n",
    "    print(f\"{i+1} : {title.get_text()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0620"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0620. 네이버 영화 순위 사이트에서 영화제목, 가격, 타입(구매 or 대여) 정보를 가져와서 TITLE, PRICE, TYPE 3개의 컬럼과 100개의 데이터포인트로 구성된 데이터프레임을 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>인사이드 아웃(패키지상품 : 더빙판 + 부가영상 추가증정)</td>\n",
       "      <td>7150</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>콩나물</td>\n",
       "      <td>1000</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>태극기 휘날리며 - 특별판</td>\n",
       "      <td>10000</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>설계자</td>\n",
       "      <td>11000</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>원피스 필름 레드</td>\n",
       "      <td>1540</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>마스크</td>\n",
       "      <td>1300</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>사운드 오브 뮤직</td>\n",
       "      <td>5500</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>마지막 한 걸음까지</td>\n",
       "      <td>500</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>흑인 오르페</td>\n",
       "      <td>500</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>수집가</td>\n",
       "      <td>2500</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               TITLE  PRICE TYPE\n",
       "0   인사이드 아웃(패키지상품 : 더빙판 + 부가영상 추가증정)   7150   구매\n",
       "1                                콩나물   1000   구매\n",
       "2                     태극기 휘날리며 - 특별판  10000   구매\n",
       "3                                설계자  11000   대여\n",
       "4                          원피스 필름 레드   1540   대여\n",
       "..                               ...    ...  ...\n",
       "81                               마스크   1300   대여\n",
       "82                         사운드 오브 뮤직   5500   구매\n",
       "83                        마지막 한 걸음까지    500   구매\n",
       "84                            흑인 오르페    500   구매\n",
       "85                               수집가   2500   대여\n",
       "\n",
       "[86 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://serieson.naver.com/v3/movie/ranking/realtime\"\n",
    "\n",
    "response = requests.get(url)\n",
    "bs = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "\n",
    "prices = bs.find_all('span', class_ = 'Price_price__GqXqo')\n",
    "price = [re.findall(r'\\d',p.text) for p in prices]\n",
    "price = [''.join(r) for r in price]\n",
    "\n",
    "\n",
    "types = bs.find_all('span', class_ = 'Price_text__pRk_f')\n",
    "type1 = [type1.text for type1 in types]\n",
    "\n",
    "\n",
    "titles = bs.find_all('span', class_ = 'Title_title__s9o0D')\n",
    "title = [title.text for title in titles]\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'TITLE' : title,\n",
    "                   'PRICE' : price,\n",
    "                   'TYPE' : type1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>인사이드 아웃(패키지상품 : 더빙판 + 부가영상 추가증정)</td>\n",
       "      <td>7,150</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>콩나물</td>\n",
       "      <td>1,000</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>태극기 휘날리며 - 특별판</td>\n",
       "      <td>10,000</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>설계자</td>\n",
       "      <td>11,000</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>원피스 필름 레드</td>\n",
       "      <td>1,540</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>마스크</td>\n",
       "      <td>1,300</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>사운드 오브 뮤직</td>\n",
       "      <td>5,500</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>마지막 한 걸음까지</td>\n",
       "      <td>500</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>흑인 오르페</td>\n",
       "      <td>500</td>\n",
       "      <td>구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>수집가</td>\n",
       "      <td>2,500</td>\n",
       "      <td>대여</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title   Price Type\n",
       "0   인사이드 아웃(패키지상품 : 더빙판 + 부가영상 추가증정)   7,150   구매\n",
       "1                                콩나물   1,000   구매\n",
       "2                     태극기 휘날리며 - 특별판  10,000   구매\n",
       "3                                설계자  11,000   대여\n",
       "4                          원피스 필름 레드   1,540   대여\n",
       "..                               ...     ...  ...\n",
       "81                               마스크   1,300   대여\n",
       "82                         사운드 오브 뮤직   5,500   구매\n",
       "83                        마지막 한 걸음까지     500   구매\n",
       "84                            흑인 오르페     500   구매\n",
       "85                               수집가   2,500   대여\n",
       "\n",
       "[86 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# URL 설정\n",
    "url = 'https://serieson.naver.com/v3/movie/ranking/realtime'\n",
    "\n",
    "# HTTP GET 요청\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # 요청이 성공했는지 확인\n",
    "\n",
    "# BeautifulSoup을 사용하여 HTML 파싱\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# 영화 제목과 가격을 저장할 리스트\n",
    "titles = []\n",
    "prices = []\n",
    "types = []\n",
    "\n",
    "# 영화 제목과 가격 추출\n",
    "movies = soup.select('.RankingList_ranking_list__N4QsH > li')\n",
    "\n",
    "for movie in movies:\n",
    "    title_tag = movie.select_one('.Title_title__s9o0D')\n",
    "    if title_tag:\n",
    "        title = title_tag.get_text(strip=True)\n",
    "    \n",
    "        # 가격 및 타입 추출\n",
    "        price_items = movie.select('.Price_price_item__tOOqb')\n",
    "        for price_item in price_items:\n",
    "            type_tag = price_item.select_one('.Price_text__pRk_f')\n",
    "            price_tag = price_item.select_one('.Price_price__GqXqo')\n",
    "            if type_tag and price_tag:\n",
    "                type_text = type_tag.get_text(strip=True)\n",
    "                price = price_tag.get_text(strip=True)\n",
    "                \n",
    "                # 가격에서 \"캐시\" 및 SVG 태그 제거\n",
    "                price = re.sub(r'캐시.*', '', price).strip()\n",
    "                \n",
    "                titles.append(title)\n",
    "                prices.append(price)\n",
    "                types.append(type_text)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Price': prices,\n",
    "    'Type': types\n",
    "})\n",
    "\n",
    "# 데이터프레임 출력\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0620. 앞에서 출력한 기사 리스트를 pandas 데이터프레임으로 변환 후 csv 파일로 저장 후 다시 불러오세요.\n",
    "\n",
    "인덱스와 기사를 컬럼으로 (2개 컬럼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이슈 지체없이 군사원조 한반도 전쟁나면 러시아 개입</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>조태용 국정원장이 민주당 의원과 오찬을 갑자기 취소한 이유는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>노컷브이 법사 운영위 1년씩 대통령도 1년씩 원구성 난항</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>이준석 전당대회 윤 대통령 의중 작용 시작 한동훈 포기 압박</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>광주 남구소식 등산로 고장 운동기구 점검 보수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>의협 올바른 의료를 위한 특별위원회 출범 전공의 자리 공석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>한동훈 23일 당대표 출마 선언 이재명 연임 도전 수순</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>채상병특검 청문회 불출석 증인 무더기 고발 예고 신원식 김계환만 사유서 제출</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>나경원 근본 깨는 이재명 대한민국 비명횡사 무조건 막아야 곧 결심</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>박원석 원희룡 출마 용산 참전신호 김근식 결선투표 노린 듯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>나경원 당 대표는 대통령과의 갈등이 겉으로 드러나면 안 돼 차별화해 대권 가겠다는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>최진녕 변호사 서용주 전 더불어민주당 상근부대변인 원 구성 놓고 여야 입장 차 대치...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>중산층까지 악영향 금투세 쟁점과 필요한 결정은</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>위계충 권폭귀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1년 전 나경원 막은 친윤 이번엔 한동훈 대항마로 키운다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    INDEX                                              TITLE\n",
       "0       1                       이슈 지체없이 군사원조 한반도 전쟁나면 러시아 개입\n",
       "1       2                  조태용 국정원장이 민주당 의원과 오찬을 갑자기 취소한 이유는\n",
       "2       3                    노컷브이 법사 운영위 1년씩 대통령도 1년씩 원구성 난항\n",
       "3       4                  이준석 전당대회 윤 대통령 의중 작용 시작 한동훈 포기 압박\n",
       "4       5                          광주 남구소식 등산로 고장 운동기구 점검 보수\n",
       "5       6                   의협 올바른 의료를 위한 특별위원회 출범 전공의 자리 공석\n",
       "6       7                     한동훈 23일 당대표 출마 선언 이재명 연임 도전 수순\n",
       "7       8         채상병특검 청문회 불출석 증인 무더기 고발 예고 신원식 김계환만 사유서 제출\n",
       "8       9               나경원 근본 깨는 이재명 대한민국 비명횡사 무조건 막아야 곧 결심\n",
       "9      10                   박원석 원희룡 출마 용산 참전신호 김근식 결선투표 노린 듯\n",
       "10     11  나경원 당 대표는 대통령과의 갈등이 겉으로 드러나면 안 돼 차별화해 대권 가겠다는 ...\n",
       "11     12  최진녕 변호사 서용주 전 더불어민주당 상근부대변인 원 구성 놓고 여야 입장 차 대치...\n",
       "12     13                          중산층까지 악영향 금투세 쟁점과 필요한 결정은\n",
       "13     14                                            위계충 권폭귀\n",
       "14     15                    1년 전 나경원 막은 친윤 이번엔 한동훈 대항마로 키운다"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36\"}\n",
    "\n",
    "\n",
    "url = 'https://news.daum.net/politics#1'\n",
    "\n",
    "r = requests.get(url,headers=headers)\n",
    "html = r.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "lines = soup.select('body > div > main > section > div > div > ul > li > div > div > strong > a')\n",
    "\n",
    "index = []\n",
    "title = []\n",
    "for i, tag in enumerate(lines,start =1):\n",
    "    text = tag.get_text().strip().replace(',','')\n",
    "    matches = re.findall('[가-힣0-9]+',text)\n",
    "    index.append(i)\n",
    "    title.append(' '.join(matches))\n",
    "\n",
    "df = pd.DataFrame({'INDEX':index,\n",
    "                   'TITLE': title})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('articles_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>이슈 지체없이 군사원조 한반도 전쟁나면 러시아 개입</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>조태용 국정원장이 민주당 의원과 오찬을 갑자기 취소한 이유는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>노컷브이 법사 운영위 1년씩 대통령도 1년씩 원구성 난항</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>이준석 전당대회 윤 대통령 의중 작용 시작 한동훈 포기 압박</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>광주 남구소식 등산로 고장 운동기구 점검 보수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>의협 올바른 의료를 위한 특별위원회 출범 전공의 자리 공석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>한동훈 23일 당대표 출마 선언 이재명 연임 도전 수순</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>채상병특검 청문회 불출석 증인 무더기 고발 예고 신원식 김계환만 사유서 제출</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>나경원 근본 깨는 이재명 대한민국 비명횡사 무조건 막아야 곧 결심</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>박원석 원희룡 출마 용산 참전신호 김근식 결선투표 노린 듯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>나경원 당 대표는 대통령과의 갈등이 겉으로 드러나면 안 돼 차별화해 대권 가겠다는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>최진녕 변호사 서용주 전 더불어민주당 상근부대변인 원 구성 놓고 여야 입장 차 대치...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>중산층까지 악영향 금투세 쟁점과 필요한 결정은</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>위계충 권폭귀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1년 전 나경원 막은 친윤 이번엔 한동훈 대항마로 키운다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    INDEX                                              TITLE\n",
       "0       1                       이슈 지체없이 군사원조 한반도 전쟁나면 러시아 개입\n",
       "1       2                  조태용 국정원장이 민주당 의원과 오찬을 갑자기 취소한 이유는\n",
       "2       3                    노컷브이 법사 운영위 1년씩 대통령도 1년씩 원구성 난항\n",
       "3       4                  이준석 전당대회 윤 대통령 의중 작용 시작 한동훈 포기 압박\n",
       "4       5                          광주 남구소식 등산로 고장 운동기구 점검 보수\n",
       "5       6                   의협 올바른 의료를 위한 특별위원회 출범 전공의 자리 공석\n",
       "6       7                     한동훈 23일 당대표 출마 선언 이재명 연임 도전 수순\n",
       "7       8         채상병특검 청문회 불출석 증인 무더기 고발 예고 신원식 김계환만 사유서 제출\n",
       "8       9               나경원 근본 깨는 이재명 대한민국 비명횡사 무조건 막아야 곧 결심\n",
       "9      10                   박원석 원희룡 출마 용산 참전신호 김근식 결선투표 노린 듯\n",
       "10     11  나경원 당 대표는 대통령과의 갈등이 겉으로 드러나면 안 돼 차별화해 대권 가겠다는 ...\n",
       "11     12  최진녕 변호사 서용주 전 더불어민주당 상근부대변인 원 구성 놓고 여야 입장 차 대치...\n",
       "12     13                          중산층까지 악영향 금투세 쟁점과 필요한 결정은\n",
       "13     14                                            위계충 권폭귀\n",
       "14     15                    1년 전 나경원 막은 친윤 이번엔 한동훈 대항마로 키운다"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.read_csv('articles_title.csv',index_col = 0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "lines = soup.select('body > div > main > section > div.main-sub > div > ul > li > strong > a')\n",
    "results = []\n",
    "for i, tag in enumerate(lines, start=1):\n",
    "    text = tag.get_text().strip().replace(',', '')\n",
    "    matches = re.findall('[가-힣0-9]+', text)\n",
    "    result = ' '.join(matches)\n",
    "    results.append({'Index':i, 'Text':result})\n",
    "    \n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.to_csv('news.csv', index=False)\n",
    "df = pd.read_csv('news.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0620. url = 'https://news.daum.net/politics#1'은 정치기사 1페이지인데 10페이지에 있는 기사를 모두 출력하세요. \n",
    "\n",
    "req, bs만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 링크가 크롤링이 불가능함 => 페이지가 넘겨지지 않음\n",
    "url = 'https://news.daum.net/politics#{}'\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,11):\n",
    "    response = requests.get(url.format(i))\n",
    "    html = BeautifulSoup(response.text,'html.parser')\n",
    "    result = html.find_all(class_ = 'link_txt')\n",
    "    for r in result:\n",
    "        print(f\"{i}번째 페이지\")\n",
    "        print(f\"기사 제목 : {r.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.daum.net/breakingnews/politics?page={}'\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,11):\n",
    "    response = requests.get(url.format(i))\n",
    "    html = BeautifulSoup(response.text,'html.parser')\n",
    "    result = html.find_all('a',class_ = 'link_txt')\n",
    "    # 불필요한 부분이있어 리스트로 추출이 되므로 슬라이싱 활용\n",
    "    result = result[7:-21]\n",
    "    for r in result:\n",
    "        print(f\"{i}번째 페이지\")\n",
    "        print(f\"기사 제목 : {r.text.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 페이지의 기사 수: 15\n",
      "2번째 페이지의 기사 수: 15\n",
      "3번째 페이지의 기사 수: 15\n",
      "4번째 페이지의 기사 수: 15\n",
      "5번째 페이지의 기사 수: 15\n",
      "6번째 페이지의 기사 수: 15\n",
      "7번째 페이지의 기사 수: 15\n",
      "8번째 페이지의 기사 수: 15\n",
      "9번째 페이지의 기사 수: 15\n",
      "10번째 페이지의 기사 수: 15\n",
      "총 기사 수: 150개\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.daum.net/breakingnews/politics?page={}'\n",
    "total_articles = 0\n",
    "\n",
    "# 제대로 출력이 된 걸 확인할 수 있다\n",
    "for i in range(1, 11):\n",
    "    response = requests.get(url.format(i))\n",
    "    html = BeautifulSoup(response.text, 'html.parser')\n",
    "    result = html.select('a.link_txt')\n",
    "    result = result[7:-21] # 정치 섹션의 기사 제목 요소 선택\n",
    "    num_articles = len(result)\n",
    "    total_articles += num_articles\n",
    "    print(f\"{i}번째 페이지의 기사 수: {num_articles}\")\n",
    "\n",
    "print(f\"총 기사 수: {total_articles}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# 다른 분이 푸신 방법\n",
    "total_articles = 0\n",
    "\n",
    "for j in range(1, 11):\n",
    "    #https://news.daum.net/breakingnews/politics?page=1\n",
    "    url = f'https://news.daum.net/breakingnews/politics?page={j}'\n",
    "    print(url)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    lines = soup.find_all('a',class_=\"link_txt\")\n",
    "    lines = lines[7:-21]\n",
    "    num_articles = len(lines)\n",
    "    total_articles += num_articles\n",
    "    print(f\"{j}번째 페이지의 기사 수: {num_articles}\")\n",
    "    for i, tag in enumerate(lines, 1):\n",
    "        text = tag.get_text().strip().replace(',', '')\n",
    "        matches = re.findall('[가-힣0-9]+', text)\n",
    "        print(f\"{i}. {' '.join(matches)}\")\n",
    "    print(f'페이지수: {j}')\n",
    "print(f\"총 기사 수: {total_articles}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "base_url = f'https://news.daum.net/breakingnews/politics?page='\n",
    "\n",
    "# 빈 리스트를 만들어 기사를 저장할 준비를 합니다\n",
    "all_articles = []\n",
    "\n",
    "# 여러 페이지를 순회하며 기사 제목을 추출\n",
    "for page_num in range(1, 11):\n",
    "    url = f'{base_url}{page_num}'\n",
    "    r = rq.get(url, headers=headers)\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 기사 제목 추출\n",
    "    lines = soup.find_all('a', class_=\"link_txt\")\n",
    "    lines = lines[7:-21]\n",
    "    articles = [line.text.strip() for line in lines]\n",
    "\n",
    "    # 추출한 기사 제목을 전체 기사 리스트에 추가\n",
    "    all_articles.extend(articles)\n",
    "\n",
    "# 인덱스 생성\n",
    "indices = range(1, len(all_articles) + 1)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({'Index': indices, 'Article': all_articles})\n",
    "\n",
    "df.to_csv('daum_politics_articles.csv', index=False)\n",
    "df = pd.read_csv('daum_politics_articles.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
