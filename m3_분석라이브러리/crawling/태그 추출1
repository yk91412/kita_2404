
## 과제 풀이

  class가 content이면서 첫번째 p태그 찾기

    => soup.find('p',class_ = 'content')

    => soup.select_one('p.content')


  다음에 위치한 모든 태그나 문자열 찾기


  => .find_next()



  이전에 위치한 모든 태그나 문자열 찾기


  => .find_previous()


=====================================================================



 - string vs. get_text() vs. text


  (1) string

  - 특징

    요소가 하나의 자식 텍스트 노드를 가지고 있는 경우에만 그 텍스트를 반환

    여러 자식 요소가 있거나 텍스트 노드가 여러 개 있는 경우 None을 반환

  
  (2) get_text() : 메서드

  요소 및 모든 하위 요소의 텍스트를 모두 추출하여 하나의 문자열로 반환


  - 특징
  
  기본적으로 하위 요소 사이에 공백을 추가


  - 옵션

  separator 매개변수를 사용하여 구분자를 지정할 수 있다

    ex) .get_text(separator = '원하는 구분자')


  strip=True 옵션을 사용하여 앞뒤 공백을 제거할 수 있다

    ex) .get_text(strip=True)


  => 함께 사용 가능

    ex) get_text(separator = '원하는 문자열', strip = True)


  (3) text : 속성

  요소 및 모든 하위 요소의 텍스트를 모두 포함하는 문자열을 반환


  - 특징
  
  get_text()와 거의 동일한 결과를 제공

  get_text()와 다르게 추가 매개변수(separator, strip)를 사용할 수 없다


=====================================================================


  - 정규표현식 활용


    re 모듈을 사용하여 특정 패턴을 가진 텍스트를 추출


    ex) 형식

    import re

    pattern = r'~'

    result = re.findall(pattern,문자열)

  => 리스트 형태로 변수에 저장




    ex) 이메일 주소 추출
  
    r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+'
  
  
    ex) url 추출
  
    r'https?://[^\s<>]+|www\.[^\s<>]+'


    ex) html 태그 내 텍스트 추출

    r'>([^<]+)<'


    ex) 정규 표현식으로 href에서 https인 것 추출하기

    li = soup.find_all(href=re.compile(r"^https://"))
    print(li,'\n')
    for e in li:
        print(e.attrs['href'])


---------------------------------------------

      .: 어떤 한 문자와 일치 (\n 제외)
    
      ^: 문자열의 시작과 일치
    
      $: 문자열의 끝과 일치
    
      *: 0번 이상 반복되는 경우와 일치
    
      +: 1번 이상 반복되는 경우와 일치
    
      ?: 0번 또는 1번 등장하는 경우와 일치
    
      {m,n}: 최소 m번, 최대 n번 반복
    
      []: 문자 집합 중 하나와 일치 (예: [abc]는 a, b, c 중 하나와 일치)
    
      |: OR 조건 (예: a|b는 a 또는 b)
    
      (...): 그룹화
    
      \d: 숫자와 일치
    
      \D: 숫자가 아닌 공백, 문자, 구두점 등 모든 문자와 일치
    
      \s: 스페이스(' '), 탭('\t'), 캐리지 리턴('\r'), 뉴라인('\n'), 폼 피드('\f') 등 공백 문자와 일치
    
      \S: 공백이 아닌 문자, 숫자, 특수 문자 등 모든 것과 일치
    
      \w: 단어 문자(문자, 숫자, 밑줄)와 일치
    
      \W: 단어 문자가 아닌 특수 문자, 공백 문자, 구두점 등과 일치

---------------------------------------------------


=====================================================================


  - urllib + bs


  import urllib.requests as rq


  html = requests.get(url)

  html = rq.urlopen(url)

  => 결과는 동일하다




=====================================================================



  - 인코딩 에러 해결

    ** chardet : "Universal Character Encoding Detector"

      => 다양한 인코딩을 감지할 수 있는 파이썬 패키지


    ** chardet.detect(response.content)['encoding']

      => response.content의 인코딩 방식을 자동으로 감지하여 반환

        이 값을 encoding 변수에 저장한 후, response.content를

        encoding 방식으로 디코딩하여 html 변수에 저장하고 출력






