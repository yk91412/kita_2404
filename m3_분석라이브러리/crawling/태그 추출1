
## 과제 풀이

  class가 content이면서 첫번째 p태그 찾기

    => soup.find('p',class_ = 'content')

    => soup.select_one('p.content')


  다음에 위치한 모든 태그나 문자열 찾기


  => .find_next()



  이전에 위치한 모든 태그나 문자열 찾기


  => .find_previous()


=====================================================================



 - string vs. get_text() vs. text


  (1) string

  - 특징

    요소가 하나의 자식 텍스트 노드를 가지고 있는 경우에만 그 텍스트를 반환

    여러 자식 요소가 있거나 텍스트 노드가 여러 개 있는 경우 None을 반환

  
  (2) get_text() : 메서드

  요소 및 모든 하위 요소의 텍스트를 모두 추출하여 하나의 문자열로 반환


  - 특징
  
  기본적으로 하위 요소 사이에 공백을 추가


  - 옵션

  separator 매개변수를 사용하여 구분자를 지정할 수 있다

    ex) .get_text(separator = '원하는 구분자')


  strip=True 옵션을 사용하여 앞뒤 공백을 제거할 수 있다

    ex) .get_text(strip=True)


  => 함께 사용 가능

    ex) get_text(separator = '원하는 문자열', strip = True)


  (3) text : 속성

  요소 및 모든 하위 요소의 텍스트를 모두 포함하는 문자열을 반환


  - 특징
  
  get_text()와 거의 동일한 결과를 제공

  get_text()와 다르게 추가 매개변수(separator, strip)를 사용할 수 없다


=====================================================================


  - 정규표현식 활용


    re 모듈을 사용하여 특정 패턴을 가진 텍스트를 추출


    ex) 형식

    import re

    pattern = r'~'

    result = re.findall(pattern,문자열)

  => 리스트 형태로 변수에 저장




    ex) 이메일 주소 추출
  
    r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+'
  
  
    ex) url 추출
  
    r'https?://[^\s<>]+|www\.[^\s<>]+'


    ex) html 태그 내 텍스트 추출

    r'>([^<]+)<'


    ex) 정규 표현식으로 href에서 https인 것 추출하기

    li = soup.find_all(href=re.compile(r"^https://"))
    print(li,'\n')
    for e in li:
        print(e.attrs['href'])


=====================================================================


  - urllib + bs












=====================================================================



  - 인코딩 에러를 해결

 chardet.detect(response.content)['encoding']은 response.content의 인코딩 방식을 자동으로 감지하여 반환하며
 이 값을 encoding 변수에 저장한 후, response.content를 이 encoding 방식으로 디코딩하여 html 변수에 저장하0고 출력


- chardet는 "Universal Character Encoding Detector"로, 다양한 인코딩을 감지할 수 있는 파이썬 패키지



