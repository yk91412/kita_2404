

GridSearchCV


지정한 매개변수 그리드를 사용하여 모든 조합에 대해 모델을 학습하고 교차 검증을 수행하여 최적의 매개변수 조합을 찾음

estimator: 사용할 모델 객체

param_grid: 탐색할 매개변수 그리드(dictionary 형태)

cv: 교차 검증을 위해 분할되는 fold 수

scoring: 성능 평가 지표를 지정

n_jobs: 병렬 처리에 사용할 CPU 코어 수

-> -1로 설정시 모든 코어 사용가능

verbose: 실행 과정을 출력할 상세도를 조절

<결과 조회 변수>

> cv_results_ : 파라미터 조합별 결과 조회

> best_params_ : 가장 좋은 성능을 낸 parameter 조합 조회

> best_estimator_ : 가장 좋은 성능을 낸 모델 반환




===========================================================

일반적으로 데이터 분할 후에 스케일링을 수행하는 것이 모델 개발 과정에서의 권장 사항

-> 데이터 누설을 방지하고, 모델의 일반화 성능을 보장

특별한 경우: 데이터 분할 전에 스케일링이 필요한 경우

모든 데이터가 동일한 도메인/분포: 데이터셋이 모두 동일한 도메인에서 수집되었고,

특성들이 유사한 분포를 가지고 있다면,

데이터를 분할하기 전에 스케일링을 수행해도 큰 문제가 없을 수도 있지만 주의 필요


===========================================================


로지스틱 회귀

모든 실수 입력에 대해 0과 1사이의 값을 반환, S자 형태를 띠는 함수


선형 회귀와 비슷하게 입력 특성의 가중치 합을 계산하나 이진 분류에 사용할 수 있는 확률로 변환

-> 이상치에 덜 민감하며, 모델이 과적합되는 것을 방지하기 위해 규제를 적용할 수 있다는 장점




특정 임계값(일반적으로 0.5)을 초과하는 경우 데이터 포인트를 해당 클래스에 할당

-> 다중 클래스에도 적용가능

  ex) 일대다 : 각 클래스에 대해 개별 이진 분류기를 학습시키고, 가장 높은 확률을 제공하느느 분류기의 클래스로 분류

    다항 로지스틱 회귀 : 각 클래스에 대한 확률을 계산하고, 가장 높은 확률을 가지는 클래스로 분류


<파라미터>

max_iter : 데이터에 대해 수렴하지 않을 때 반복 횟수를 늘려서 해결 가능


solver : 메모리 사용 최소화

    -> lbfgs



