## 분류모델

train_tests_split random 11




[DecisionTreeClassifier] - 분류
[DecisionTreeRegresssion] - 회귀


** 결정 트리

  <규칙>

  최대한 많은 데이터 세트가 해당 분류에 속할 수 있도록 


  <구조>

  규칙 노드(규칙 조건)

  리프 노드(결정된 클래스 값)

  서브 트리(새로운 규칙 조건마다 규칙 노드 기반의 서브트리 생성)


  <하이퍼 파라미터>



** 지니계수



=========================================================

** KNN

  : 가장 속성이 비슷한 이웃을 먼저 찾음




=========================================================

** SVM(서포트 벡터머신)



  <kernel>

선형 커널 (Linear Kernel)
선형 커널은 간단하고 빠르며, 데이터가 선형적으로 구분될 때 좋은 성능을 보입니다.
Wine 데이터셋에서 선형 커널이 적합한지 확인해보면, 일부 클래스 간의 분류가 충분하지 않을 수 있습니다.

다항식 커널 (Polynomial Kernel)
다항식 커널은 비선형적으로 분포된 데이터를 더 잘 처리할 수 있습니다.
차수가 증가함에 따라 모델이 더 복잡해지고, 데이터의 패턴을 더 잘 포착할 수 있지만, 과적합의 위험이 있습니다.

RBF 커널 (RBF Kernel)
RBF 커널은 비선형적인 경계를 가진 데이터에서 가장 효과적입니다.
Wine 데이터셋의 복잡한 패턴을 잘 포착할 수 있으며, 높은 성능을 기대할 수 있습니다.






  <C 매개변수>



=========================================================

앙상블 학습





=========================================================

Random Forest




