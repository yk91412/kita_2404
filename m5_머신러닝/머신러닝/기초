
머신러닝

 컴퓨터가 명시적으로 프로그래밍되지 않고도 데이터에서 학습하고 예측 가능


- 핵심사항

 데이터: 머신러닝은 데이터를 기반으로 학습. 즉 좋은 데이터가 좋은 모델의 핵심

 알고리즘: 머신러닝에는 다양한 알고리즘이 있습니다. 각 알고리즘은 특정 유형의 문제에 더 적합

 하이퍼파라미터: 알고리즘의 성능에 영향을 미치는 매개변수 / 실험을 통해 최적화

 평가 지표: 모델의 성능을 측정하는 방법

  1) 분류모델:

    정확도, 정밀도, 재현율,  F1 점수


  2) 회귀모델 :

    평균 절대 오차, 회귀 작업의 평균 제곱근 오차와 같은 메트릭을 포함


- 유형

  1) 지도 학습: 

  선형 회귀, 로지스틱 회귀, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅, SVM(Support Vector Machines) 및 k-NN(k-nearest neighbours)
  
  과 같은 알고리즘은 레이블이 지정된 학습 데이터를 사용하여

  입력 기능을 기반으로 대상 변수를 예측하는 데 사용

  (명확한 답이 있음)

  => 알려진 입력 데이터 세트(특징)와 데이터에 대한 알려진 응답(대상 또는 레이블)을 입력받아 모델을 훈련하여

     새 데이터에 대한 응답에 대한 합리적인 예측을 생성

  ** 두 가지 유형의 문제에 사용

회귀:

대상 또는 종속 변수가 연속적이거나 정렬된 전체 값일 때 사용.
회귀에 사용되는 알고리즘에는 선형 회귀, 결정 트리, 랜덤 포레스트 및 GBM 계열의 회귀트리 모델 포함.

=> ex) 주택 가격 예측

-> mse(Mean Squared Error) 예측값과 실제값의 차이의 제곱의 평균 :

  값이 작을수록 모델의 예측이 정확함을 의미


분류:

분류는 대상 변수가 범주형일 때,
간단히 말해서 입력 데이터를 범주로 분류할 때 사용.
분류에 사용되는 알고리즘에는 Logistic Regression, Naive Bayes, Decision Trees, Random Forests, Support Vector Machines
및 Neural Networks 및 GBM 계열의 Boosting 모델 포함.

=> ex) 붓꽃의 종류를 분류


알고리즘이 작동하는 방식
데이터 수집: 데이터를 수집하고 전처리. 데이터는 feature와 label로 구분. 이를 위해 사용되는 데이터는 출력 데이터 세트도 제공되기 때문에 레이블이 지정된 데이터라고 한다.
모델 훈련: 알고리즘은 훈련 데이터를 통해 학습. feature와 label 간의 패턴 또는 관계를 발견하려고 시도.
모델 예측: 모델이 훈련되면 본 적이 없는 새로운 데이터의 결과를 예측하는 데 사용. 이 새 데이터에 대한 입력을 테스트 데이터라고 한다.
평가: 모델의 예측을 실제 값과 비교하여 모델의 정확도를 평가. 정확도, 정밀도, 재현율, F1 점수(분류용), 평균 절대 오차(MAE), 평균 제곱 오차(MSE), 평균 제곱근 오차(RMSE)(회귀용)와 같은 다양한 메트릭이 모델을 평가하는 데 사용.
조정: 모델의 성능이 만족스럽지 않으면 모델로 돌아가 하이퍼파라미터를 조정하거나 다른 모델을 모두 선택 가능
예측: 만족스러운 성능이 달성되면 이제 모델을 사용하여 보이지 않는 새로운 데이터를 예측할 수 있다.









  2) 비지도 학습: 
  k-평균, 계층적 클러스터링 및 DBSCAN과 같은 클러스터링 기법 및 PCA(Principal Component Analysis), LDA, SVD 등의 차원 축소 기법
  (답은 없고 데이터만 있음)




- 비지도 학습(Unsupervised Learning)은 레이블이 지정되지 않은 데이터를 사용하여 모델을 학습하는 방법
- 지도 학습과 달리 비지도 학습은 모델의 성능을 평가하기 위한 레이블이 불필요.
- 비지도 학습 알고리즘  
    - 클러스터링: 클러스터링 알고리즘에는 K-평균, 평균-점 클러스터링, 밀도기반 군집(DBSCAN) 등
    - 차원 축소: 차원 축소 알고리즘에는 주성분 분석(PCA), 선형판별분석(LDA),   특이값 분해(SVD) 등
    
- 비지도 학습은 머신 러닝에서 강력한 도구입니다. 비지도 학습은 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용.





  3) 강화 학습:

  에이전트가 조치를 취하고 그 대가로 보상이나 처벌을 받음으로써 환경에서 행동하는 방법을 배우는 기계 학습으로
목표는 시간이 지남에 따라 누적 보상을 최대화하는 것

  4) 신경망 및 딥러닝:
신경망, 역전파 및 CNN(Convolutional Neural Networks), RNN(Recurrent Neural Networks),
Long Short-Term 메모리(LSTM) 네트워크

  5) 자연어 :

트랜스포머 기반의 BERT, GPT Series의 발전으로 자연어 처리의 급속한 발전 진행

  6) LLM(Large Language Model) :
거대 생성 언어모델 기반의 ChatGPT 시리즈의 발전으로 인간과 상호작용할 수 있는 수준으로 발전

  7) 비전:

Yolo를 이용한 다양한 객체탐지솔루션이 폭넓게 활용되고 Stable Diffusion이 이미지 생성을 위한 주요 솔루션으로 확대 예정  


============================================================


사이킷런





============================================================



X : 입력 데이터 셋

=> ex) 주택 가격을 예측하는 경우 주택의 여러 특성(면적, 방의 수, 위치 등)을 포함한 데이터

y : 출력 데이터 또는 레이블

=> ex) 각 주택의 가격을 나타내는 값


 X_train은 훈련 데이터의 입력 특성을, y_train은 훈련 데이터의 실제 출력값(정답)


데이터의 분할: train_test_split() 함수를 사용하여 데이터를 훈련 세트와 테스트 세트로 나눌 때,
데이터가 무작위로 섞이기 때문에 각 세트에 포함되는 데이터의 구성이 달라질 수 있습니다.
이는 각 실행에서 훈련 데이터와 테스트 데이터의 성격이 약간씩 달라질 수 있음을 의미합니다.

데이터의 크기: 데이터셋의 크기가 작거나 특정 패턴이나 극단적인 샘플이 포함되어 있을 경우,
다른 데이터셋 구성으로 인해 모델의 성능이 달라질 수 있습니다.

모델의 초기화: 일부 모델은 초기화 과정에서 난수를 사용하여 가중치를 초기화하거나 데이터를 분할하는 등의 과정에서
랜덤 요소를 포함할 수 있습니다. 이러한 경우에도 동일한 코드와 설정을 사용하더라도 각 실행에서 결과가 달라질 수 있습니다.









============================================================
