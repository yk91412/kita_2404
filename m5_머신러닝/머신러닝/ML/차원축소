
다중공선성

  독립변수들 간에 높은 상관관계가 있을 때 발생하는 현상

    ->하나 또는 그 이상의 독립변수와 선형적으로 매우 밀접하게 관련되어있음을 의미

  문제점:

  1. 계수 추정의 불안정성 : 회귀 계수(회귀 모델에서 독립 변수의 가중치)의 추정치가 불안정하게 되어,

    작은 데이터 변경에 의해 추정치가 크게 변동될 가능성

  2. 해석의 어려움 : 개별적으로 분리하여 해석하기 어려움

    -> 어떤 변수가 종속 변수에 미치는 영향을 파아갛기 어려움

  3. 과적합 : 새 데이터에 대해서는 예측 성능 떨어질 수도

  진단:

  1. 분산팽창인자 : VIF는 독립변수가 다른 독립변수에 의해 얼마나 설명되는지를 측정하는 지표


  -> 10이상일시 높은 다중공산성으로 판단

  2. 상관 행렬 : 0.8 이상


  해결법:

  1. 차원 축소

  2. 변수 제거

  3. 릿지,라쏘 회귀 : 정규화 기법 사용


==================================================================

차원 축소

1. PCA

  데이터의 공분산 행렬을 이용하여 주성분을 찾고, 데이터의 분산을 최대한 보존하면서 차원을 축소

  -> 공분산 행렬의 고유값과 고유벡터를 찾아서 고유벡터를 주성분으로 사용하여 데이터를 변환

  => 데이터의 변동성을 설명하는데 직관적


2. SVD

1) svd

  행렬을 세 개의 행렬의 곱으로 분해하는 방법으로 원본 정보가 보존되며 행렬의 구조 분석이 가능


  => 차원 축소 외에도 데이터 압축, 노이즈 제거 등에 사용



2) truncatedsvd


  상위 k개의 특이값만을 사용하여 데이터의 근사치를 구함

  -> 데이터의 주요 정보를 보존하면서 차원을 축소

  => 대규모 데이터에 대해 계산 효율성이 좋음


3. NMF


  비음수 행렬 W와 H를 사용하여 원래 행렬 V를 근사하는 방법

  -> 비음수 제약으로 인해 데이터의 구성 요소를 직관적으로 해석

  => 주로 이미지, 텍스트 데이터에서 특징 추출 및 차원 축소에 사용


4. 선형대수식

5. LDA

  pca와 유사하나 입력 데이터의 결정값 클래스를 최대한 분리할 수 있는

  축을 찾는 방식으로 차원축소함


