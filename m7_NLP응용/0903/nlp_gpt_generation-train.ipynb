{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ratsgo/nlpbook/blob/master/examples/sentence_generation/train_colab.ipynb","timestamp":1673055773610}],"gpuClass":"premium","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5265feabda9e445997b81bd21799922a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3eeb152a9ecf422e9ab37b1058122777","IPY_MODEL_8d32bf1a1878488693ed62843fbbb966","IPY_MODEL_0477c3ae486b4d4288ffe7ff5550b732"],"layout":"IPY_MODEL_1dca1915f1e748fba9942710ee307e68"}},"3eeb152a9ecf422e9ab37b1058122777":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd69bdbf6ab4766a810ed492320b13b","placeholder":"​","style":"IPY_MODEL_28d910072988407581116fe895ad6fe8","value":"pytorch_model.bin: 100%"}},"8d32bf1a1878488693ed62843fbbb966":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0317d4ddc2414f37a612dd3999b58521","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2482323ca53c43279395a2b05f6da9ec","value":513302779}},"0477c3ae486b4d4288ffe7ff5550b732":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c38759b1a3648548cf2ede548e20ed3","placeholder":"​","style":"IPY_MODEL_27c4312bb0474a9289c782f18c0b6b5a","value":" 513M/513M [00:06&lt;00:00, 141MB/s]"}},"1dca1915f1e748fba9942710ee307e68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbd69bdbf6ab4766a810ed492320b13b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28d910072988407581116fe895ad6fe8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0317d4ddc2414f37a612dd3999b58521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2482323ca53c43279395a2b05f6da9ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c38759b1a3648548cf2ede548e20ed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27c4312bb0474a9289c782f18c0b6b5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"219f00576242491ea928957621d03266":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bae0f476456d4b608df7e4d5ce238065","IPY_MODEL_1471d01c3a454e5fa8cee85ebd70da34","IPY_MODEL_9b3ae72b47cb4f0db90521e11b0d968b"],"layout":"IPY_MODEL_a531aee297b94be089c0ccc7004c298a"}},"bae0f476456d4b608df7e4d5ce238065":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74b975f1ee648919de462751383a84e","placeholder":"​","style":"IPY_MODEL_b6019e9293a34d7682ab07542250aad0","value":"Epoch 2: 100%"}},"1471d01c3a454e5fa8cee85ebd70da34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66cba5a70d1f4b9389bf0d6ddb76037d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_682834720a5f4faa97fab8229ee5f871","value":1}},"9b3ae72b47cb4f0db90521e11b0d968b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_677f0e05d75247ceb2a3fcaa5e629075","placeholder":"​","style":"IPY_MODEL_b23eefb4e2644fb89b7302235948a416","value":" 6251/6251 [1:19:47&lt;00:00,  1.31it/s, loss=2.22, v_num=0, val_loss=2.300]"}},"a531aee297b94be089c0ccc7004c298a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b74b975f1ee648919de462751383a84e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6019e9293a34d7682ab07542250aad0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66cba5a70d1f4b9389bf0d6ddb76037d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"682834720a5f4faa97fab8229ee5f871":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"677f0e05d75247ceb2a3fcaa5e629075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b23eefb4e2644fb89b7302235948a416":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"870b399b29bd4266a9ff954433ea26ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cce4176b3fd74edf8ce6282fa95990ca","IPY_MODEL_2e08b8088f9d4cf5a3cfd55cddf8ed83","IPY_MODEL_80e379a4c9f040d7ae310771a46c3436"],"layout":"IPY_MODEL_735461e4445648a893b21ffeec298951"}},"cce4176b3fd74edf8ce6282fa95990ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecc1e8d53faa4d4c8f0e210c13c2d45c","placeholder":"​","style":"IPY_MODEL_a76158e7110b4343945b3a3430819e81","value":"Validation DataLoader 0: 100%"}},"2e08b8088f9d4cf5a3cfd55cddf8ed83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6d4e9fb9ab345b0827f1ea6c7209c4e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1c64bf5215a4af19ecc10a69e28a1b6","value":1}},"80e379a4c9f040d7ae310771a46c3436":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e63c4048f844a2ca0a9078a77f7e93f","placeholder":"​","style":"IPY_MODEL_438911e183da424a81af92e3f4ee1874","value":" 1563/1563 [02:22&lt;00:00, 10.99it/s]"}},"735461e4445648a893b21ffeec298951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ecc1e8d53faa4d4c8f0e210c13c2d45c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a76158e7110b4343945b3a3430819e81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6d4e9fb9ab345b0827f1ea6c7209c4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c64bf5215a4af19ecc10a69e28a1b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e63c4048f844a2ca0a9078a77f7e93f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"438911e183da424a81af92e3f4ee1874":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e0ce248f8844356a8d111afa1f9e887":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf5acea95ca04b8dbdd0b14a1cdab045","IPY_MODEL_a49e17f56dce48bb99af29d12afe0800","IPY_MODEL_3bbf0ca3cb4f489888986c0ab84a6bb9"],"layout":"IPY_MODEL_b35c2a98b1924d66afca881948b3f138"}},"cf5acea95ca04b8dbdd0b14a1cdab045":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1291f1d2b9ea431da53451be2735365e","placeholder":"​","style":"IPY_MODEL_7550366285334736ac71fd64f2ad521d","value":"Validation DataLoader 0: 100%"}},"a49e17f56dce48bb99af29d12afe0800":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8629fa8d3df4089974c8892f48de22f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bc69be126b446c297bf7da1e401c503","value":1}},"3bbf0ca3cb4f489888986c0ab84a6bb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63428c3192ed45479a58c4c59e28c309","placeholder":"​","style":"IPY_MODEL_a4c6cd986e5d494db0d7ba6ce09ccef0","value":" 1563/1563 [02:22&lt;00:00, 10.98it/s]"}},"b35c2a98b1924d66afca881948b3f138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"1291f1d2b9ea431da53451be2735365e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7550366285334736ac71fd64f2ad521d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8629fa8d3df4089974c8892f48de22f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bc69be126b446c297bf7da1e401c503":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63428c3192ed45479a58c4c59e28c309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4c6cd986e5d494db0d7ba6ce09ccef0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca8d4c2a6cb04e599fae8a0569678fe1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52444ab164af48bc91ce461666d58d40","IPY_MODEL_e2de162c5bed4a54b68537dd7a4b2370","IPY_MODEL_57cefdc5175b4f74ab488ea5eb2610c2"],"layout":"IPY_MODEL_e0586091f10545acb41048e6759e1fde"}},"52444ab164af48bc91ce461666d58d40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23ca9c2b39cb4840955d8267adc8f067","placeholder":"​","style":"IPY_MODEL_3860f534574541318310f3f21ef7639d","value":"Validation DataLoader 0: 100%"}},"e2de162c5bed4a54b68537dd7a4b2370":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eac4524d6974d2885ceaae5539caa73","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57c30d2f2b15406a8c16bd95b08e0fd4","value":1}},"57cefdc5175b4f74ab488ea5eb2610c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53c1226fe86a4a568f63e48b11015eed","placeholder":"​","style":"IPY_MODEL_2c9f35316618471a9925a6be6000387b","value":" 1563/1563 [02:22&lt;00:00, 10.95it/s]"}},"e0586091f10545acb41048e6759e1fde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"23ca9c2b39cb4840955d8267adc8f067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3860f534574541318310f3f21ef7639d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8eac4524d6974d2885ceaae5539caa73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57c30d2f2b15406a8c16bd95b08e0fd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53c1226fe86a4a568f63e48b11015eed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c9f35316618471a9925a6be6000387b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["GPT(Generative Pre-trained Transformer) 모델의 전체 과정을 설명하기 위해, 토크나이저 사용부터 모델링, 평가, 추론에 이르기까지의 단계별로 설명하겠습니다. GPT는 주로 자연어 생성에 사용되는 언어 모델로, 문맥을 이해하고 새로운 텍스트를 생성하는 데 탁월한 성능을 보입니다.\n","\n","### 1. **토크나이저 사용**\n","토크나이저는 텍스트를 처리하기 위한 첫 번째 단계입니다. GPT 모델의 경우 **Byte-Pair Encoding (BPE)** 방식의 서브워드 기반 토크나이저를 주로 사용합니다. 텍스트를 모델이 이해할 수 있는 형식(토큰)으로 변환한 후, 해당 토큰을 숫자 ID로 매핑하는 작업을 수행합니다.\n","\n","#### 1.1 **텍스트 입력 토크나이징**\n","GPT에서 입력 텍스트는 서브워드 수준에서 분리됩니다. 예를 들어, \"The quick brown fox jumps over the lazy dog\"이라는 문장이 입력되면, 토크나이저가 이 문장을 서브워드 단위로 분리하고, 각 서브워드에 해당하는 고유한 정수 ID로 변환합니다.\n","\n","```python\n","from transformers import GPT2Tokenizer\n","\n","# GPT 토크나이저 로드\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# 문장 토크나이징\n","input_text = \"The quick brown fox jumps over the lazy dog\"\n","tokens = tokenizer.tokenize(input_text)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(tokens)     # ['The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog']\n","print(token_ids)  # [464, 1560, 635, 987, 1599, 544, 464, 17239, 3290]\n","```\n","GPT-2 모델의 vocab 사전에는 총 50,257개의 토큰이 포함되어 있습니다. 따라서, ID의 수는 0부터 50,256까지 총 50,257개입니다. 이 숫자는 GPT-2 모델이 사용하는 BPE (Byte Pair Encoding) 토크나이저에서 생성된 모든 토큰을 포함합니다.\n","\n","이러한 토큰화 과정은 텍스트를 서브워드 단위로 쪼개고, 각 서브워드에 고유한 ID를 부여함으로써 모델이 텍스트 데이터를 수치화된 형태로 처리할 수 있도록 돕습니다.\n","\n","#### 1.2 **모델 입력 생성**\n","토큰화된 텍스트는 모델에 입력으로 제공되기 위해 시퀀스 길이를 맞추기 위해 패딩이 적용되거나, 문장 시작을 알리는 `<|endoftext|>` 같은 특별 토큰이 추가될 수 있습니다.\n","\n","### 2. **모델링**\n","GPT는 **Transformer의 디코더(decoder)** 아키텍처만을 사용하여, 주어진 시퀀스에서 다음 단어를 예측하는 방식으로 작동합니다. GPT의 핵심은 **자기 주의 메커니즘(self-attention mechanism)**을 통해 문맥 정보를 학습하는 것입니다.\n","\n","#### 2.1 **모델 구조**\n","GPT 모델은 여러 개의 디코더 레이어로 구성되며, 각 레이어는 자기 주의 메커니즘과 피드포워드 뉴럴 네트워크로 이루어져 있습니다. 자기 주의 메커니즘을 통해 각 단어가 문맥 내 다른 단어들과의 관계를 학습하게 됩니다.\n","\n","- **Self-Attention**: 문장 내의 각 단어가 문맥에서 다른 단어들과 어떻게 연관되는지를 학습합니다.\n","- **Layer Normalization**: 학습을 안정화하고, 성능을 향상시키기 위해 레이어 별로 입력을 정규화합니다.\n","- **Feedforward Neural Network**: Self-Attention을 통과한 데이터를 처리하여 모델의 출력을 생성합니다.\n","\n","#### 2.2 **학습 (Pre-training)**\n","GPT 모델은 대량의 텍스트 데이터를 사용하여 사전 학습(pre-training)됩니다. 이 과정에서 모델은 주어진 문맥에서 다음 단어를 예측하는 **자기 지도 학습(self-supervised learning)**을 수행합니다.\n","\n","- 입력 시퀀스에서 이전 단어들을 기반으로, 다음에 나올 단어를 예측합니다.\n","- **손실 함수**는 Cross-Entropy Loss를 사용하여 예측된 단어와 실제 단어 간의 차이를 측정합니다.\n","- 이 과정에서 모델은 문장의 구조, 문맥 및 언어 패턴을 학습합니다.\n","\n","### 3. **평가 (Evaluation)**\n","모델을 평가하기 위한 과정에서는 보통 **Perplexity**라는 지표가 많이 사용됩니다. Perplexity는 언어 모델이 주어진 단어 시퀀스를 얼마나 잘 예측했는지를 나타내는 지표입니다. 더 구체적으로, 이는 모델이 예측한 확률 분포의 \"확신도\"를 나타냅니다. Perplexity가 낮을수록, 모델이 높은 확신을 가지고 올바르게 단어를 예측했다는 뜻입니다. 반대로, Perplexity가 높으면, 모델이 예측에 대해 확신이 낮았거나 틀린 예측을 많이 했다는 의미입니다.\n","\n","- **Perplexity**: $PP(W) = exp \\left( - \\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i|w_{1:i-1}) \\right)$\n","  - N은 문장의 단어 개수이고, $P(w_i|w_{1:i-1})$는 이전 단어들을 기반으로 모델이 예측한 다음 단어의 확률입니다.\n","\n","### 4. **추론 (Inference)**\n","GPT 모델은 주로 **언어 생성** 또는 **다음 단어 예측** 작업에 사용됩니다. 추론 단계에서, 모델은 주어진 문장을 기반으로 다음에 나올 단어를 생성하며, 이 과정을 반복하여 원하는 길이의 텍스트를 생성합니다.\n","\n","#### 4.1 **Greedy Search**\n","가장 확률이 높은 단어를 매번 선택하여 시퀀스를 생성하는 방식입니다. 빠르지만, 다양성 없이 항상 가장 가능성이 높은 단어만을 선택하므로 문장의 창의성이 떨어질 수 있습니다.\n","\n","#### 4.2 **Beam Search**\n","여러 개의 경로를 동시에 탐색하며, 최적의 시퀀스를 찾는 방식입니다. 더 창의적이고 다양한 문장을 생성할 수 있지만, 계산 비용이 높을 수 있습니다.\n","\n","#### 4.3 **Top-k Sampling 및 Nucleus Sampling**\n","모델이 예측한 단어 확률 분포에서 상위 k개의 단어만 고려하는 방식이 **Top-k Sampling**이며, 확률 누적 합이 일정 값(p)에 도달할 때까지 단어들을 고려하는 방식이 **Nucleus Sampling (Top-p Sampling)**입니다. 이 방식은 좀 더 다양하고 자연스러운 문장을 생성할 수 있습니다.\n","\n","```python\n","from transformers import GPT2LMHeadModel\n","\n","# GPT2 모델과 토크나이저 로드\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# 입력 텍스트\n","input_text = \"Once upon a time\"\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","\n","# 모델로 텍스트 생성\n","output = model.generate(input_ids, max_length=50, num_return_sequences=1, top_k=50, top_p=0.95)\n","\n","# 생성된 텍스트 디코딩\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(generated_text)\n","```\n","\n","### 5. **최종 요약**\n","1. **토크나이저 사용**: 텍스트를 서브워드로 분리하고, 이를 고유한 토큰 ID로 변환합니다.\n","2. **모델링**: Transformer의 디코더 아키텍처를 사용하여 주어진 문맥에서 다음 단어를 예측합니다.\n","3. **평가**: 주로 Perplexity를 사용하여 모델 성능을 평가합니다.\n","4. **추론**: 다양한 기법(Greedy, Beam Search, Top-k Sampling, Nucleus Sampling)을 통해 텍스트를 생성합니다.\n","\n","이러한 단계들을 통해 GPT는 입력 문장을 이해하고, 그에 기반하여 의미 있고 자연스러운 텍스트를 생성할 수 있습니다."],"metadata":{"id":"Nb1pNlPL1wlO"}},{"cell_type":"code","metadata":{"id":"0U3MeuPe4HkP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725324797829,"user_tz":-540,"elapsed":23694,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"86aaece2-b3a4-4e3a-9b6b-0cc4e9f3df5d"},"source":["# 의존성 패키지 설치하기\n","%pip install pip==24.0.0 -q\n","%pip install ratsnlp -q"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mDEPRECATION: pytorch-lightning 1.6.1 has a non-standard dependency specifier torch>=1.8.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"ML-ubp246uzI"},"source":["# 각종 설정\n","모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iS0FDj64Xje0","executionInfo":{"status":"ok","timestamp":1725324769986,"user_tz":-540,"elapsed":25125,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"cdbfafe2-4e9f-4fb0-b245-4c57df5c2787"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["https://github.com/ratsgo/ratsnlp/blob/master/ratsnlp/nlpbook/generation/arguments.py"],"metadata":{"id":"wgm1O_VywwDI"}},{"cell_type":"code","metadata":{"id":"dtoPBSH4v31j","executionInfo":{"status":"ok","timestamp":1725326170493,"user_tz":-540,"elapsed":7000,"user":{"displayName":"윤경","userId":"08475145638068530881"}}},"source":["import torch\n","from ratsnlp.nlpbook.generation import GenerationTrainArguments\n","args = GenerationTrainArguments(\n","    pretrained_model_name=\"skt/kogpt2-base-v2\", # 40GB 이상의 텍스트로 학습된 한국어 디코더(decoder) 언어모델\n","    downstream_corpus_name=\"nsmc\",\n","    downstream_model_dir=\"/content/drive/MyDrive/kdt_240424/m7_nlp응용/checkpoint-generation1\",\n","    max_seq_length=32,\n","    batch_size=32 if torch.cuda.is_available() else 4,\n","    learning_rate=5e-5,\n","    epochs=3,\n","    tpu_cores=0 if torch.cuda.is_available() else 8, #gpu가 사용 가능하면 tpu를 사용하지 않지만, GPU가 없는 경우 TPU를 8개 코어로 설정해 학습 수행\n","    seed=7,\n",")"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import torch\n","from ratsnlp.nlpbook.generation import GenerationTrainArguments\n","args = GenerationTrainArguments(\n","    pretrained_model_name=\"skt/kogpt2-base-v2\", # 40GB 이상의 텍스트로 학습된 한국어 디코더(decoder) 언어모델\n","    downstream_corpus_name=\"nsmc\",\n","    downstream_model_dir=\"/content/drive/MyDrive/kdt_240424/m7_nlp응용/generation-train1\",\n","    max_seq_length=32,\n","    batch_size=32 if torch.cuda.is_available() else 4,\n","    learning_rate=5e-5,\n","    epochs=3,\n","    tpu_cores=0 if torch.cuda.is_available() else 8, #gpu가 사용 가능하면 tpu를 사용하지 않지만, GPU가 없는 경우 TPU를 8개 코어로 설정해 학습 수행\n","    seed=7,\n",")"],"metadata":{"id":"6K2XL-2GdgX6","executionInfo":{"status":"ok","timestamp":1725326367032,"user_tz":-540,"elapsed":412,"user":{"displayName":"윤경","userId":"08475145638068530881"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48RjaTAr7D4M"},"source":["# 랜덤 시드 고정\n","학습 재현을 위해 랜덤 시드를 고정합니다."]},{"cell_type":"code","metadata":{"id":"HuacSUSd7JRf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326371789,"user_tz":-540,"elapsed":416,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"28a0930a-9aee-4904-a132-b5a900645e36"},"source":["from ratsnlp import nlpbook\n","nlpbook.set_seed(args)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["set seed: 7\n"]}]},{"cell_type":"markdown","metadata":{"id":"FeTvf0bc9bbV"},"source":["# 로거 설정\n","메세지 출력 등을 위한 logger를 설정합니다. 로거는 프로그램이 실행되는 동안 발생하는 다양한 정보를 기록합니다. 이 정보에는 디버깅 정보, 오류 메시지, 경고, 정보성 메시지 등이 포함됩니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"251gdehZ9iPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326374177,"user_tz":-540,"elapsed":523,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"9572ba11-3d9b-4774-f47f-dae2521860c0"},"source":["nlpbook.set_logger(args)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:ratsnlp:Training/evaluation parameters GenerationTrainArguments(pretrained_model_name='skt/kogpt2-base-v2', downstream_task_name='sentence-generation', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/content/drive/MyDrive/kdt_240424/m7_nlp응용/generation-train1', max_seq_length=32, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)\n","INFO:ratsnlp:Training/evaluation parameters GenerationTrainArguments(pretrained_model_name='skt/kogpt2-base-v2', downstream_task_name='sentence-generation', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/content/drive/MyDrive/kdt_240424/m7_nlp응용/generation-train1', max_seq_length=32, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)\n","INFO:ratsnlp:Training/evaluation parameters GenerationTrainArguments(pretrained_model_name='skt/kogpt2-base-v2', downstream_task_name='sentence-generation', downstream_corpus_name='nsmc', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/content/drive/MyDrive/kdt_240424/m7_nlp응용/generation-train1', max_seq_length=32, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, cpu_workers=2, fp16=False, tpu_cores=0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"DqUazvWL7Pry"},"source":["# 말뭉치 다운로드\n","실습에 사용할 말뭉치(NSMC)를 다운로드합니다."]},{"cell_type":"code","metadata":{"id":"opyaJgPA7Zxi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326377516,"user_tz":-540,"elapsed":409,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"61f62a69-93af-4235-e1c0-f38dfe8af03d"},"source":["from Korpora import Korpora\n","Korpora.fetch(\n","    corpus_name=args.downstream_corpus_name,\n","    root_dir=args.downstream_corpus_root_dir,\n","    force_download=args.force_download,\n",")"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[Korpora] Corpus `nsmc` is already installed at /content/Korpora/nsmc/ratings_train.txt\n","[Korpora] Corpus `nsmc` is already installed at /content/Korpora/nsmc/ratings_test.txt\n"]}]},{"cell_type":"code","source":["!ls /content/Korpora/nsmc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEHd9WNbKPPB","executionInfo":{"status":"ok","timestamp":1725326379597,"user_tz":-540,"elapsed":405,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"ee5dea55-2bba-4e7f-ddd6-76113e1db7da"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["ratings_test.txt  ratings_train.txt\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# NSMC 학습 데이터 파일 경로\n","file_path = '/content/Korpora/nsmc/ratings_train.txt'\n","\n","# 데이터 파일 읽기 (탭으로 구분된 CSV 파일 형식)\n","data = pd.read_csv(file_path, sep='\\t')\n","\n","# 데이터의 첫 몇 줄을 출력\n","print(data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0YkdbgVKUPf","executionInfo":{"status":"ok","timestamp":1725326383388,"user_tz":-540,"elapsed":444,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"162f6c22-c996-4c55-fc14-7e036e5b68b1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n"]}]},{"cell_type":"code","source":["# NSMC 테스트 데이터 파일 경로\n","file_path = '/content/Korpora/nsmc/ratings_test.txt'\n","\n","# 데이터 파일 읽기 (탭으로 구분된 CSV 파일 형식)\n","test_data = pd.read_csv(file_path, sep='\\t')\n","\n","# 데이터의 첫 몇 줄을 출력\n","print(test_data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAflDgaKMkSi","executionInfo":{"status":"ok","timestamp":1725326387189,"user_tz":-540,"elapsed":529,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"8893888c-7a9d-4daf-9d95-5672cf927780"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["        id                                           document  label\n","0  6270596                                                굳 ㅋ      1\n","1  9274899                               GDNTOPCLASSINTHECLUB      0\n","2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n"]}]},{"cell_type":"markdown","metadata":{"id":"2DnwLCKB7cRq"},"source":["# 토크나이저 준비\n","토큰화를 수행하는 토크나이저를 선언합니다"]},{"cell_type":"code","metadata":{"id":"OlcoBivi7hIY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326392663,"user_tz":-540,"elapsed":416,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"2aa220b9-d5a4-4d53-a201-c283c56cf4eb"},"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\n","    args.pretrained_model_name,\n","    eos_token=\"</s>\", # end-of-sentence token\n",")\n","# eos_token: 문장 마지막에 붙이는 스페셜 토큰(end of sentence)으로 SK텔레콤이 모델을 프리트레인할 때 이렇게 지정했기 때문에 같은 방식으로 사용"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}]},{"cell_type":"markdown","metadata":{"id":"hZbLCM5e7i6g"},"source":["# 학습데이터 구축\n","학습데이터를 만듭니다."]},{"cell_type":"code","metadata":{"id":"v9s8znA17ovP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326417749,"user_tz":-540,"elapsed":18753,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"599fe786-98b8-4e9f-cfd3-685a3020cac7"},"source":["from ratsnlp.nlpbook.generation import NsmcCorpus, GenerationDataset\n","from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n","corpus = NsmcCorpus()\n","train_dataset = GenerationDataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"train\",\n",")\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    sampler=RandomSampler(train_dataset, replacement=False),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n","INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n","INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n","INFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt\n","INFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt\n","INFO:ratsnlp:loading train data... LOOKING AT /content/Korpora/nsmc/ratings_train.txt\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences [took 9.311 s]\n","INFO:ratsnlp:tokenize sentences [took 9.311 s]\n","INFO:ratsnlp:tokenize sentences [took 9.311 s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 부정 아 더빙.. 진짜 짜증나네요 목소리\n","INFO:ratsnlp:sentence: 부정 아 더빙.. 진짜 짜증나네요 목소리\n","INFO:ratsnlp:sentence: 부정 아 더빙.. 진짜 짜증나네요 목소리\n","INFO:ratsnlp:tokens: ▁부정 ▁아 ▁더 빙 .. ▁진짜 ▁짜 증 나 네 요 ▁목소리 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁아 ▁더 빙 .. ▁진짜 ▁짜 증 나 네 요 ▁목소리 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁아 ▁더 빙 .. ▁진짜 ▁짜 증 나 네 요 ▁목소리 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 9050, 9267, 7700, 9705, 23971, 12870, 8262, 7055, 7098, 8084, 48213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 긍정 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n","INFO:ratsnlp:sentence: 긍정 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n","INFO:ratsnlp:sentence: 긍정 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n","INFO:ratsnlp:tokens: ▁긍정 ▁흠 ... 포 스터 보고 ▁초 딩 영화 줄 .... 오 버 연기 조차 ▁가볍 지 ▁않 구나 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁긍정 ▁흠 ... 포 스터 보고 ▁초 딩 영화 줄 .... 오 버 연기 조차 ▁가볍 지 ▁않 구나 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁긍정 ▁흠 ... 포 스터 보고 ▁초 딩 영화 줄 .... 오 버 연기 조차 ▁가볍 지 ▁않 구나 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 19243, 29045, 8658, 11211, 11213, 9206, 7301, 14558, 8239, 10765, 8052, 7621, 31542, 15651, 20364, 8263, 9111, 12226, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 부정 너무재밓었다그래서보는것을추천한다\n","INFO:ratsnlp:sentence: 부정 너무재밓었다그래서보는것을추천한다\n","INFO:ratsnlp:sentence: 부정 너무재밓었다그래서보는것을추천한다\n","INFO:ratsnlp:tokens: ▁부정 ▁너무 재 <unk> 었 다 그래 서 보는 것 을 추천 한다 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁너무 재 <unk> 었 다 그래 서 보는 것 을 추천 한다 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁너무 재 <unk> 었 다 그래 서 보는 것 을 추천 한다 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 12371, 8170, 5, 8017, 7182, 19561, 7788, 12399, 6860, 8137, 32217, 10013, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 부정 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n","INFO:ratsnlp:sentence: 부정 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n","INFO:ratsnlp:sentence: 부정 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n","INFO:ratsnlp:tokens: ▁부정 ▁교도 소 ▁이야기 구 먼 ▁ .. 솔 직 히 ▁재 미는 ▁없다. . 평 점 ▁조정 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁교도 소 ▁이야기 구 먼 ▁ .. 솔 직 히 ▁재 미는 ▁없다. . 평 점 ▁조정 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁교도 소 ▁이야기 구 먼 ▁ .. 솔 직 히 ▁재 미는 ▁없다. . 평 점 ▁조정 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 25365, 7824, 11120, 6919, 7514, 739, 9705, 7828, 8264, 8811, 9150, 16504, 22316, 389, 8656, 8191, 11840, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 긍정 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n","INFO:ratsnlp:sentence: 긍정 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n","INFO:ratsnlp:sentence: 긍정 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n","INFO:ratsnlp:tokens: ▁긍정 ▁사이 몬 페 그의 ▁익살 스런 ▁연기가 ▁돋보 였던 ▁영화 ! 스파 이 더 맨 에서 ▁늙 어 보 이기 만 ▁했던 ▁커 스 틴 ▁던 스트가 ▁너무나 도 ▁이 뻐\n","INFO:ratsnlp:tokens: ▁긍정 ▁사이 몬 페 그의 ▁익살 스런 ▁연기가 ▁돋보 였던 ▁영화 ! 스파 이 더 맨 에서 ▁늙 어 보 이기 만 ▁했던 ▁커 스 틴 ▁던 스트가 ▁너무나 도 ▁이 뻐\n","INFO:ratsnlp:tokens: ▁긍정 ▁사이 몬 페 그의 ▁익살 스런 ▁연기가 ▁돋보 였던 ▁영화 ! 스파 이 더 맨 에서 ▁늙 어 보 이기 만 ▁했던 ▁커 스 틴 ▁던 스트가 ▁너무나 도 ▁이 뻐\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 9435, 7543, 8643, 28657, 34499, 19912, 43245, 21778, 10463, 10584, 376, 19193, 8146, 7208, 7503, 9023, 17231, 8006, 7652, 11864, 7489, 13885, 10114, 7877, 8610, 13727, 38593, 25793, 7235, 9018, 7722])\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 6.715 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 6.715 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_train_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 6.715 s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"SOAACuBY7vem"},"source":["# 테스트 데이터 구축\n","학습 중에 평가할 테스트 데이터를 구축합니다."]},{"cell_type":"code","metadata":{"id":"mcm1tgfq7y84","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326440578,"user_tz":-540,"elapsed":7569,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"6eb905ab-ed04-406f-f6c4-47ddb0b85719"},"source":["val_dataset = GenerationDataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"test\",\n",")\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=args.batch_size,\n","    sampler=SequentialSampler(val_dataset),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")\n"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n","INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n","INFO:ratsnlp:Creating features from dataset file at /content/Korpora/nsmc\n","INFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt\n","INFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt\n","INFO:ratsnlp:loading test data... LOOKING AT /content/Korpora/nsmc/ratings_test.txt\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences, it could take a lot of time...\n","INFO:ratsnlp:tokenize sentences [took 3.629 s]\n","INFO:ratsnlp:tokenize sentences [took 3.629 s]\n","INFO:ratsnlp:tokenize sentences [took 3.629 s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 긍정 굳 ㅋ\n","INFO:ratsnlp:sentence: 긍정 굳 ㅋ\n","INFO:ratsnlp:sentence: 긍정 굳 ㅋ\n","INFO:ratsnlp:tokens: ▁긍정 ▁굳 ▁ ᄏ </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁긍정 ▁굳 ▁ ᄏ </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁긍정 ▁굳 ▁ ᄏ </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[16420, 12969, 739, 605, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 부정 GDNTOPCLASSINTHECLUB\n","INFO:ratsnlp:sentence: 부정 GDNTOPCLASSINTHECLUB\n","INFO:ratsnlp:sentence: 부정 GDNTOPCLASSINTHECLUB\n","INFO:ratsnlp:tokens: ▁부정 ▁G D N T OP C LA S S I N T H EC L U B </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁G D N T OP C LA S S I N T H EC L U B </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁G D N T OP C LA S S I N T H EC L U B </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 10528, 410, 420, 426, 33287, 409, 36502, 425, 425, 415, 420, 426, 414, 23361, 418, 427, 408, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 부정 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n","INFO:ratsnlp:sentence: 부정 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n","INFO:ratsnlp:sentence: 부정 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n","INFO:ratsnlp:tokens: ▁부정 ▁뭐 야 ▁이 ▁평 점 들은 .... ▁나쁘 진 ▁않지만 ▁10 점 ▁짜 리는 ▁더 더 욱 ▁아니 잖 아 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁뭐 야 ▁이 ▁평 점 들은 .... ▁나쁘 진 ▁않지만 ▁10 점 ▁짜 리는 ▁더 더 욱 ▁아니 잖 아 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁뭐 야 ▁이 ▁평 점 들은 .... ▁나쁘 진 ▁않지만 ▁10 점 ▁짜 리는 ▁더 더 욱 ▁아니 잖 아 </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 46651, 7991, 9018, 9195, 8191, 9177, 10765, 50432, 8265, 17219, 9292, 8191, 12870, 9409, 9267, 7208, 8093, 9320, 8162, 7965, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 부정 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n","INFO:ratsnlp:sentence: 부정 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n","INFO:ratsnlp:sentence: 부정 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n","INFO:ratsnlp:tokens: ▁부정 ▁지루 하지는 ▁않은 데 ▁완전 ▁막 장 임 ... ▁돈 주고 ▁보 기에는 .... </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁지루 하지는 ▁않은 데 ▁완전 ▁막 장 임 ... ▁돈 주고 ▁보 기에는 .... </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁지루 하지는 ▁않은 데 ▁완전 ▁막 장 임 ... ▁돈 주고 ▁보 기에는 .... </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40886, 14752, 10091, 7220, 10253, 9730, 8168, 8152, 29045, 10855, 11545, 9049, 11351, 10765, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:sentence: 부정 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n","INFO:ratsnlp:sentence: 부정 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n","INFO:ratsnlp:sentence: 부정 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n","INFO:ratsnlp:tokens: ▁부정 ▁3D 만 ▁아니었 어도 ▁별 ▁다섯 ▁개 ▁ 줬 을 텐 데 .. ▁왜 ▁3D 로 ▁나와 서 ▁제 ▁심 기를 ▁불편 하게 ▁하 죠 ? ? </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁3D 만 ▁아니었 어도 ▁별 ▁다섯 ▁개 ▁ 줬 을 텐 데 .. ▁왜 ▁3D 로 ▁나와 서 ▁제 ▁심 기를 ▁불편 하게 ▁하 죠 ? ? </s> </s> </s> </s>\n","INFO:ratsnlp:tokens: ▁부정 ▁3D 만 ▁아니었 어도 ▁별 ▁다섯 ▁개 ▁ 줬 을 텐 데 .. ▁왜 ▁3D 로 ▁나와 서 ▁제 ▁심 기를 ▁불편 하게 ▁하 죠 ? ? </s> </s> </s> </s>\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1])\n","INFO:ratsnlp:features: GenerationFeatures(input_ids=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], labels=[11775, 40944, 7489, 44224, 12821, 9686, 13265, 9086, 739, 8245, 8137, 8550, 7220, 9705, 10401, 40944, 7426, 12964, 7788, 9037, 9327, 9368, 19092, 9124, 9078, 8234, 406, 406, 1, 1, 1, 1])\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 2.157 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 2.157 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/nsmc/cached_test_PreTrainedTokenizerFast_32_nsmc_sentence-generation [took 2.157 s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"HztMCywb70e9"},"source":["# 모델 초기화\n","프리트레인이 완료된 GPT2 모델을 읽고, 문장 생성 모델을 초기화합니다.\n","\n","huggingface/transformers<br>\n","\n","https://github.com/huggingface/transformers/blob/v4.25.1/src/transformers/models/gpt2/modeling_gpt2.py#L945"]},{"cell_type":"code","metadata":{"id":"staYwMx88MWQ","colab":{"base_uri":"https://localhost:8080/","height":143,"referenced_widgets":["5265feabda9e445997b81bd21799922a","3eeb152a9ecf422e9ab37b1058122777","8d32bf1a1878488693ed62843fbbb966","0477c3ae486b4d4288ffe7ff5550b732","1dca1915f1e748fba9942710ee307e68","dbd69bdbf6ab4766a810ed492320b13b","28d910072988407581116fe895ad6fe8","0317d4ddc2414f37a612dd3999b58521","2482323ca53c43279395a2b05f6da9ec","3c38759b1a3648548cf2ede548e20ed3","27c4312bb0474a9289c782f18c0b6b5a"]},"executionInfo":{"status":"ok","timestamp":1725326463584,"user_tz":-540,"elapsed":11202,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"b2f32cae-c8f4-4c78-d7be-6d405f3ffe8e"},"source":["from transformers import GPT2LMHeadModel\n","model = GPT2LMHeadModel.from_pretrained(\n","    args.pretrained_model_name\n",")"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5265feabda9e445997b81bd21799922a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(checkpoint_file, map_location=\"cpu\")\n"]}]},{"cell_type":"markdown","metadata":{"id":"lYtJXijM8PN8"},"source":["# 학습 준비\n","Task와 Trainer를 준비합니다."]},{"cell_type":"code","metadata":{"id":"-FFn4MSz8SWu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326506607,"user_tz":-540,"elapsed":405,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"2e43ee07-448b-4786-8b4e-754c7a1897dd"},"source":["# https://github.com/ratsgo/ratsnlp/blob/master/ratsnlp/nlpbook/generation/task.py\n","from ratsnlp.nlpbook.generation import GenerationTask\n","task = GenerationTask(model, args)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py:2046: DeprecationWarning: `torch.distributed._sharded_tensor` will be deprecated, use `torch.distributed._shard.sharded_tensor` instead\n","  from torch.distributed._sharded_tensor import pre_load_state_dict_hook, state_dict_hook\n"]}]},{"cell_type":"code","metadata":{"id":"18W4vRtR8UTx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725326515281,"user_tz":-540,"elapsed":405,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"cdd1fa42-3eaa-422b-c014-408f210612ee"},"source":["# ratsnlp/ratsnlp/nlpbook/trainer.py\n","\n","trainer = nlpbook.get_trainer(args)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"markdown","metadata":{"id":"KteHdhBT8X0e"},"source":["# 학습\n","준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/gdrive/My Drive/nlpbook/checkpoint-generation`)에 저장됩니다."]},{"cell_type":"code","metadata":{"id":"SDr3M_nF8l7M","colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["219f00576242491ea928957621d03266","bae0f476456d4b608df7e4d5ce238065","1471d01c3a454e5fa8cee85ebd70da34","9b3ae72b47cb4f0db90521e11b0d968b","a531aee297b94be089c0ccc7004c298a","b74b975f1ee648919de462751383a84e","b6019e9293a34d7682ab07542250aad0","66cba5a70d1f4b9389bf0d6ddb76037d","682834720a5f4faa97fab8229ee5f871","677f0e05d75247ceb2a3fcaa5e629075","b23eefb4e2644fb89b7302235948a416","870b399b29bd4266a9ff954433ea26ee","cce4176b3fd74edf8ce6282fa95990ca","2e08b8088f9d4cf5a3cfd55cddf8ed83","80e379a4c9f040d7ae310771a46c3436","735461e4445648a893b21ffeec298951","ecc1e8d53faa4d4c8f0e210c13c2d45c","a76158e7110b4343945b3a3430819e81","b6d4e9fb9ab345b0827f1ea6c7209c4e","f1c64bf5215a4af19ecc10a69e28a1b6","6e63c4048f844a2ca0a9078a77f7e93f","438911e183da424a81af92e3f4ee1874","0e0ce248f8844356a8d111afa1f9e887","cf5acea95ca04b8dbdd0b14a1cdab045","a49e17f56dce48bb99af29d12afe0800","3bbf0ca3cb4f489888986c0ab84a6bb9","b35c2a98b1924d66afca881948b3f138","1291f1d2b9ea431da53451be2735365e","7550366285334736ac71fd64f2ad521d","f8629fa8d3df4089974c8892f48de22f","1bc69be126b446c297bf7da1e401c503","63428c3192ed45479a58c4c59e28c309","a4c6cd986e5d494db0d7ba6ce09ccef0","ca8d4c2a6cb04e599fae8a0569678fe1","52444ab164af48bc91ce461666d58d40","e2de162c5bed4a54b68537dd7a4b2370","57cefdc5175b4f74ab488ea5eb2610c2","e0586091f10545acb41048e6759e1fde","23ca9c2b39cb4840955d8267adc8f067","3860f534574541318310f3f21ef7639d","8eac4524d6974d2885ceaae5539caa73","57c30d2f2b15406a8c16bd95b08e0fd4","53c1226fe86a4a568f63e48b11015eed","2c9f35316618471a9925a6be6000387b"]},"executionInfo":{"status":"ok","timestamp":1725331308756,"user_tz":-540,"elapsed":4790238,"user":{"displayName":"윤경","userId":"08475145638068530881"}},"outputId":"d65f74f4-1aa2-442d-9b89-198c6fec99df"},"source":["trainer.fit(\n","    task,\n","    train_dataloaders=train_dataloader,\n","    val_dataloaders=val_dataloader,\n",")"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/drive/MyDrive/kdt_240424/m7_nlp응용/generation-train1/lightning_logs\n","INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py:380: RuntimeWarning: Found unsupported keys in the optimizer configuration: {'scheduler'}\n","  rank_zero_warn(\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name  | Type            | Params\n","------------------------------------------\n","0 | model | GPT2LMHeadModel | 125 M \n","------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"219f00576242491ea928957621d03266"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"870b399b29bd4266a9ff954433ea26ee"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e0ce248f8844356a8d111afa1f9e887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca8d4c2a6cb04e599fae8a0569678fe1"}},"metadata":{}}]},{"cell_type":"code","source":["# 폴더 복사\n","!cp -r /gdrive/My Drive/nlpbook/checkpoint-generation2 /gdrive/MyDrive/kdt_231026/m7_nlp응용/gpt"],"metadata":{"id":"whp9fYfkWCET"},"execution_count":null,"outputs":[]}]}